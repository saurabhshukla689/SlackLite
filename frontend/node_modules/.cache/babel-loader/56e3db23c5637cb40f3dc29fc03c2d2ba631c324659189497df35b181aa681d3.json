{"ast":null,"code":"import { equal } from \"@wry/equality\";\nimport { getOperationName, graphQLResultHasError } from \"@apollo/client/utilities/internal\";\nimport { invariant } from \"@apollo/client/utilities/invariant\";\nconst IGNORE = {};\nconst destructiveMethodCounts = new WeakMap();\nfunction wrapDestructiveCacheMethod(cache, methodName) {\n  const original = cache[methodName];\n  if (typeof original === \"function\") {\n    // @ts-expect-error this is just too generic to be typed correctly\n    cache[methodName] = function () {\n      destructiveMethodCounts.set(cache,\n      // The %1e15 allows the count to wrap around to 0 safely every\n      // quadrillion evictions, so there's no risk of overflow. To be\n      // clear, this is more of a pedantic principle than something\n      // that matters in any conceivable practical scenario.\n      (destructiveMethodCounts.get(cache) + 1) % 1e15);\n      // @ts-expect-error this is just too generic to be typed correctly\n      return original.apply(this, arguments);\n    };\n  }\n}\nconst queryInfoIds = new WeakMap();\n// A QueryInfo object represents a single network request, either initiated\n// from the QueryManager or from an ObservableQuery.\n// It will only ever be used for a single network call.\n// It is responsible for reporting results to the cache, merging and in a no-cache\n// scenario accumulating the response.\nexport class QueryInfo {\n  // TODO remove soon - this should be able to be handled by cancelling old operations before starting new ones\n  lastRequestId = 1;\n  cache;\n  queryManager;\n  id;\n  observableQuery;\n  incremental;\n  constructor(queryManager, observableQuery) {\n    const cache = this.cache = queryManager.cache;\n    const id = (queryInfoIds.get(queryManager) || 0) + 1;\n    queryInfoIds.set(queryManager, id);\n    this.id = id + \"\";\n    this.observableQuery = observableQuery;\n    this.queryManager = queryManager;\n    // Track how often cache.evict is called, since we want eviction to\n    // override the feud-stopping logic in the markQueryResult method, by\n    // causing shouldWrite to return true. Wrapping the cache.evict method\n    // is a bit of a hack, but it saves us from having to make eviction\n    // counting an official part of the ApolloCache API.\n    if (!destructiveMethodCounts.has(cache)) {\n      destructiveMethodCounts.set(cache, 0);\n      wrapDestructiveCacheMethod(cache, \"evict\");\n      wrapDestructiveCacheMethod(cache, \"modify\");\n      wrapDestructiveCacheMethod(cache, \"reset\");\n    }\n  }\n  /**\n  * @internal\n  * For feud-preventing behaviour, `lastWrite` should be shared by all `QueryInfo` instances of an `ObservableQuery`.\n  * In the case of a standalone `QueryInfo`, we will keep a local version.\n  * \n  * @deprecated This is an internal API and should not be used directly. This can be removed or changed at any time.\n  */\n  _lastWrite;\n  get lastWrite() {\n    return (this.observableQuery || this)._lastWrite;\n  }\n  set lastWrite(value) {\n    (this.observableQuery || this)._lastWrite = value;\n  }\n  resetLastWrite() {\n    this.lastWrite = void 0;\n  }\n  shouldWrite(result, variables) {\n    const {\n      lastWrite\n    } = this;\n    return !(lastWrite &&\n    // If cache.evict has been called since the last time we wrote this\n    // data into the cache, there's a chance writing this result into\n    // the cache will repair what was evicted.\n    lastWrite.dmCount === destructiveMethodCounts.get(this.cache) && equal(variables, lastWrite.variables) && equal(result.data, lastWrite.result.data));\n  }\n  get hasNext() {\n    return this.incremental ? this.incremental.hasNext : false;\n  }\n  maybeHandleIncrementalResult(cacheData, incoming, query) {\n    const {\n      incrementalHandler\n    } = this.queryManager;\n    if (incrementalHandler.isIncrementalResult(incoming)) {\n      this.incremental ||= incrementalHandler.startRequest({\n        query\n      });\n      return this.incremental.handle(cacheData, incoming);\n    }\n    return incoming;\n  }\n  markQueryResult(incoming, {\n    document: query,\n    variables,\n    errorPolicy,\n    cacheWriteBehavior\n  }) {\n    const diffOptions = {\n      query,\n      variables,\n      returnPartialData: true,\n      optimistic: true\n    };\n    // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n    // requests. To allow future notify timeouts, diff and dirty are reset as well.\n    this.observableQuery?.[\"resetNotifications\"]();\n    const skipCache = cacheWriteBehavior === 0 /* CacheWriteBehavior.FORBID */;\n    const lastDiff = skipCache ? undefined : this.cache.diff(diffOptions);\n    let result = this.maybeHandleIncrementalResult(lastDiff?.result, incoming, query);\n    if (skipCache) {\n      return result;\n    }\n    if (shouldWriteResult(result, errorPolicy)) {\n      // Using a transaction here so we have a chance to read the result\n      // back from the cache before the watch callback fires as a result\n      // of writeQuery, so we can store the new diff quietly and ignore\n      // it when we receive it redundantly from the watch callback.\n      this.cache.batch({\n        onWatchUpdated: (\n        // all additional options on ObservableQuery.CacheWatchOptions are\n        // optional so we can use the type here\n        watch, diff) => {\n          if (watch.watcher === this.observableQuery) {\n            // see comment on `lastOwnDiff` for explanation\n            watch.lastOwnDiff = diff;\n          }\n        },\n        update: cache => {\n          if (this.shouldWrite(result, variables)) {\n            cache.writeQuery({\n              query,\n              data: result.data,\n              variables,\n              overwrite: cacheWriteBehavior === 1 /* CacheWriteBehavior.OVERWRITE */\n            });\n            this.lastWrite = {\n              result,\n              variables,\n              dmCount: destructiveMethodCounts.get(this.cache)\n            };\n          } else {\n            // If result is the same as the last result we received from\n            // the network (and the variables match too), avoid writing\n            // result into the cache again. The wisdom of skipping this\n            // cache write is far from obvious, since any cache write\n            // could be the one that puts the cache back into a desired\n            // state, fixing corruption or missing data. However, if we\n            // always write every network result into the cache, we enable\n            // feuds between queries competing to update the same data in\n            // incompatible ways, which can lead to an endless cycle of\n            // cache broadcasts and useless network requests. As with any\n            // feud, eventually one side must step back from the brink,\n            // letting the other side(s) have the last word(s). There may\n            // be other points where we could break this cycle, such as\n            // silencing the broadcast for cache.writeQuery (not a good\n            // idea, since it just delays the feud a bit) or somehow\n            // avoiding the network request that just happened (also bad,\n            // because the server could return useful new data). All\n            // options considered, skipping this cache write seems to be\n            // the least damaging place to break the cycle, because it\n            // reflects the intuition that we recently wrote this exact\n            // result into the cache, so the cache *should* already/still\n            // contain this data. If some other query has clobbered that\n            // data in the meantime, that's too bad, but there will be no\n            // winners if every query blindly reverts to its own version\n            // of the data. This approach also gives the network a chance\n            // to return new data, which will be written into the cache as\n            // usual, notifying only those queries that are directly\n            // affected by the cache updates, as usual. In the future, an\n            // even more sophisticated cache could perhaps prevent or\n            // mitigate the clobbering somehow, but that would make this\n            // particular cache write even less important, and thus\n            // skipping it would be even safer than it is today.\n            if (lastDiff && lastDiff.complete) {\n              // Reuse data from the last good (complete) diff that we\n              // received, when possible.\n              result = {\n                ...result,\n                data: lastDiff.result\n              };\n              return;\n            }\n            // If the previous this.diff was incomplete, fall through to\n            // re-reading the latest data with cache.diff, below.\n          }\n          const diff = cache.diff(diffOptions);\n          // If we're allowed to write to the cache, and we can read a\n          // complete result from the cache, update result.data to be the\n          // result from the cache, rather than the raw network result.\n          // Set without setDiff to avoid triggering a notify call, since\n          // we have other ways of notifying for this result.\n          if (diff.complete) {\n            result = {\n              ...result,\n              data: diff.result\n            };\n          }\n        }\n      });\n    } else {\n      this.lastWrite = void 0;\n    }\n    return result;\n  }\n  markMutationResult(incoming, mutation, cache = this.cache) {\n    const cacheWrites = [];\n    const skipCache = mutation.cacheWriteBehavior === 0 /* CacheWriteBehavior.FORBID */;\n    let result = this.maybeHandleIncrementalResult(skipCache ? undefined : cache.diff({\n      id: \"ROOT_MUTATION\",\n      // The cache complains if passed a mutation where it expects a\n      // query, so we transform mutations and subscriptions to queries\n      // (only once, thanks to this.transformCache).\n      query: this.queryManager.getDocumentInfo(mutation.document).asQuery,\n      variables: mutation.variables,\n      optimistic: false,\n      returnPartialData: true\n    }).result, incoming, mutation.document);\n    if (mutation.errorPolicy === \"ignore\") {\n      result = {\n        ...result,\n        errors: []\n      };\n    }\n    if (graphQLResultHasError(result) && mutation.errorPolicy === \"none\") {\n      return Promise.resolve(result);\n    }\n    const getResultWithDataState = () => ({\n      ...result,\n      dataState: this.hasNext ? \"streaming\" : \"complete\"\n    });\n    if (!skipCache && shouldWriteResult(result, mutation.errorPolicy)) {\n      cacheWrites.push({\n        result: result.data,\n        dataId: \"ROOT_MUTATION\",\n        query: mutation.document,\n        variables: mutation.variables\n      });\n      const {\n        updateQueries\n      } = mutation;\n      if (updateQueries) {\n        this.queryManager.getObservableQueries(\"all\").forEach(observableQuery => {\n          const queryName = observableQuery && observableQuery.queryName;\n          if (!queryName || !Object.hasOwnProperty.call(updateQueries, queryName)) {\n            return;\n          }\n          const updater = updateQueries[queryName];\n          const {\n            query: document,\n            variables\n          } = observableQuery;\n          // Read the current query result from the store.\n          const {\n            result: currentQueryResult,\n            complete\n          } = observableQuery.getCacheDiff({\n            optimistic: false\n          });\n          if (complete && currentQueryResult) {\n            // Run our reducer using the current query result and the mutation result.\n            const nextQueryResult = updater(currentQueryResult, {\n              mutationResult: getResultWithDataState(),\n              queryName: document && getOperationName(document) || void 0,\n              queryVariables: variables\n            });\n            // Write the modified result back into the store if we got a new result.\n            if (nextQueryResult) {\n              cacheWrites.push({\n                result: nextQueryResult,\n                dataId: \"ROOT_QUERY\",\n                query: document,\n                variables\n              });\n            }\n          }\n        });\n      }\n    }\n    let refetchQueries = mutation.refetchQueries;\n    if (typeof refetchQueries === \"function\") {\n      refetchQueries = refetchQueries(getResultWithDataState());\n    }\n    if (cacheWrites.length > 0 || (refetchQueries || \"\").length > 0 || mutation.update || mutation.onQueryUpdated || mutation.removeOptimistic) {\n      const results = [];\n      this.queryManager.refetchQueries({\n        updateCache: cache => {\n          if (!skipCache) {\n            cacheWrites.forEach(write => cache.write(write));\n          }\n          // If the mutation has some writes associated with it then we need to\n          // apply those writes to the store by running this reducer again with\n          // a write action.\n          const {\n            update\n          } = mutation;\n          // Determine whether result is a SingleExecutionResult,\n          // or the final ExecutionPatchResult.\n          if (update) {\n            if (!skipCache) {\n              // Re-read the ROOT_MUTATION data we just wrote into the cache\n              // (the first cache.write call in the cacheWrites.forEach loop\n              // above), so field read functions have a chance to run for\n              // fields within mutation result objects.\n              const diff = cache.diff({\n                id: \"ROOT_MUTATION\",\n                // The cache complains if passed a mutation where it expects a\n                // query, so we transform mutations and subscriptions to queries\n                // (only once, thanks to this.transformCache).\n                query: this.queryManager.getDocumentInfo(mutation.document).asQuery,\n                variables: mutation.variables,\n                optimistic: false,\n                returnPartialData: true\n              });\n              if (diff.complete) {\n                result = {\n                  ...result,\n                  data: diff.result\n                };\n              }\n            }\n            // If we've received the whole response, call the update function.\n            if (!this.hasNext) {\n              update(cache, result, {\n                context: mutation.context,\n                variables: mutation.variables\n              });\n            }\n          }\n          // TODO Do this with cache.evict({ id: 'ROOT_MUTATION' }) but make it\n          // shallow to allow rolling back optimistic evictions.\n          if (!skipCache && !mutation.keepRootFields && !this.hasNext) {\n            cache.modify({\n              id: \"ROOT_MUTATION\",\n              fields(value, {\n                fieldName,\n                DELETE\n              }) {\n                return fieldName === \"__typename\" ? value : DELETE;\n              }\n            });\n          }\n        },\n        include: refetchQueries,\n        // Write the final mutation.result to the root layer of the cache.\n        optimistic: false,\n        // Remove the corresponding optimistic layer at the same time as we\n        // write the final non-optimistic result.\n        removeOptimistic: mutation.removeOptimistic,\n        // Let the caller of client.mutate optionally determine the refetching\n        // behavior for watched queries after the mutation.update function runs.\n        // If no onQueryUpdated function was provided for this mutation, pass\n        // null instead of undefined to disable the default refetching behavior.\n        onQueryUpdated: mutation.onQueryUpdated || null\n      }).forEach(result => results.push(result));\n      if (mutation.awaitRefetchQueries || mutation.onQueryUpdated) {\n        // Returning a promise here makes the mutation await that promise, so we\n        // include results in that promise's work if awaitRefetchQueries or an\n        // onQueryUpdated function was specified.\n        return Promise.all(results).then(() => result);\n      }\n    }\n    return Promise.resolve(result);\n  }\n  markMutationOptimistic(optimisticResponse, mutation) {\n    const data = typeof optimisticResponse === \"function\" ? optimisticResponse(mutation.variables, {\n      IGNORE\n    }) : optimisticResponse;\n    if (data === IGNORE) {\n      return false;\n    }\n    this.cache.recordOptimisticTransaction(cache => {\n      try {\n        this.markMutationResult({\n          data\n        }, mutation, cache);\n      } catch (error) {\n        invariant.error(error);\n      }\n    }, this.id);\n    return true;\n  }\n  markSubscriptionResult(result, {\n    document,\n    variables,\n    errorPolicy,\n    cacheWriteBehavior\n  }) {\n    if (cacheWriteBehavior !== 0 /* CacheWriteBehavior.FORBID */) {\n      if (shouldWriteResult(result, errorPolicy)) {\n        this.cache.write({\n          query: document,\n          result: result.data,\n          dataId: \"ROOT_SUBSCRIPTION\",\n          variables: variables\n        });\n      }\n      this.queryManager.broadcastQueries();\n    }\n  }\n}\nfunction shouldWriteResult(result, errorPolicy = \"none\") {\n  const ignoreErrors = errorPolicy === \"ignore\" || errorPolicy === \"all\";\n  let writeWithErrors = !graphQLResultHasError(result);\n  if (!writeWithErrors && ignoreErrors && result.data) {\n    writeWithErrors = true;\n  }\n  return writeWithErrors;\n}","map":{"version":3,"names":["equal","getOperationName","graphQLResultHasError","invariant","IGNORE","destructiveMethodCounts","WeakMap","wrapDestructiveCacheMethod","cache","methodName","original","set","get","apply","arguments","queryInfoIds","QueryInfo","lastRequestId","queryManager","id","observableQuery","incremental","constructor","has","_lastWrite","lastWrite","value","resetLastWrite","shouldWrite","result","variables","dmCount","data","hasNext","maybeHandleIncrementalResult","cacheData","incoming","query","incrementalHandler","isIncrementalResult","startRequest","handle","markQueryResult","document","errorPolicy","cacheWriteBehavior","diffOptions","returnPartialData","optimistic","skipCache","lastDiff","undefined","diff","shouldWriteResult","batch","onWatchUpdated","watch","watcher","lastOwnDiff","update","writeQuery","overwrite","complete","markMutationResult","mutation","cacheWrites","getDocumentInfo","asQuery","errors","Promise","resolve","getResultWithDataState","dataState","push","dataId","updateQueries","getObservableQueries","forEach","queryName","Object","hasOwnProperty","call","updater","currentQueryResult","getCacheDiff","nextQueryResult","mutationResult","queryVariables","refetchQueries","length","onQueryUpdated","removeOptimistic","results","updateCache","write","context","keepRootFields","modify","fields","fieldName","DELETE","include","awaitRefetchQueries","all","then","markMutationOptimistic","optimisticResponse","recordOptimisticTransaction","error","markSubscriptionResult","broadcastQueries","ignoreErrors","writeWithErrors"],"sources":["/home/saurabh-shukla/Desktop/Slack Lite/frontend/node_modules/@apollo/src/core/QueryInfo.ts"],"sourcesContent":["import { equal } from \"@wry/equality\";\nimport type { DocumentNode, FormattedExecutionResult } from \"graphql\";\n\nimport type { ApolloCache, Cache } from \"@apollo/client/cache\";\nimport type { IgnoreModifier } from \"@apollo/client/cache\";\nimport type { Incremental } from \"@apollo/client/incremental\";\nimport type { ApolloLink } from \"@apollo/client/link\";\nimport type { Unmasked } from \"@apollo/client/masking\";\nimport type { DeepPartial } from \"@apollo/client/utilities\";\nimport {\n  getOperationName,\n  graphQLResultHasError,\n} from \"@apollo/client/utilities/internal\";\nimport { invariant } from \"@apollo/client/utilities/invariant\";\n\nimport type { ApolloClient } from \"./ApolloClient.js\";\nimport type { ObservableQuery } from \"./ObservableQuery.js\";\nimport type { QueryManager } from \"./QueryManager.js\";\nimport type {\n  DataValue,\n  DefaultContext,\n  InternalRefetchQueriesInclude,\n  MutationQueryReducer,\n  MutationUpdaterFunction,\n  NormalizedExecutionResult,\n  OnQueryUpdated,\n  OperationVariables,\n  TypedDocumentNode,\n} from \"./types.js\";\nimport type { ErrorPolicy } from \"./watchQueryOptions.js\";\n\ntype UpdateQueries<TData> = ApolloClient.MutateOptions<\n  TData,\n  any,\n  any\n>[\"updateQueries\"];\n\nconst IGNORE = {} as IgnoreModifier;\n\nexport const enum CacheWriteBehavior {\n  FORBID,\n  OVERWRITE,\n  MERGE,\n}\n\ninterface LastWrite {\n  result: FormattedExecutionResult<any>;\n  variables: ApolloClient.WatchQueryOptions[\"variables\"];\n  dmCount: number | undefined;\n}\n\nconst destructiveMethodCounts = new WeakMap<ApolloCache, number>();\n\ninterface OperationInfo<\n  TData,\n  TVariables extends OperationVariables,\n  AllowedCacheWriteBehavior = CacheWriteBehavior,\n> {\n  document: DocumentNode | TypedDocumentNode<TData, TVariables>;\n  variables: TVariables;\n  errorPolicy: ErrorPolicy;\n  cacheWriteBehavior: AllowedCacheWriteBehavior;\n}\n\nfunction wrapDestructiveCacheMethod(\n  cache: ApolloCache,\n  methodName: \"evict\" | \"modify\" | \"reset\"\n) {\n  const original = cache[methodName];\n  if (typeof original === \"function\") {\n    // @ts-expect-error this is just too generic to be typed correctly\n    cache[methodName] = function () {\n      destructiveMethodCounts.set(\n        cache,\n        // The %1e15 allows the count to wrap around to 0 safely every\n        // quadrillion evictions, so there's no risk of overflow. To be\n        // clear, this is more of a pedantic principle than something\n        // that matters in any conceivable practical scenario.\n        (destructiveMethodCounts.get(cache)! + 1) % 1e15\n      );\n      // @ts-expect-error this is just too generic to be typed correctly\n      return original.apply(this, arguments);\n    };\n  }\n}\n\nconst queryInfoIds = new WeakMap<QueryManager, number>();\n\n// A QueryInfo object represents a single network request, either initiated\n// from the QueryManager or from an ObservableQuery.\n// It will only ever be used for a single network call.\n// It is responsible for reporting results to the cache, merging and in a no-cache\n// scenario accumulating the response.\nexport class QueryInfo<\n  TData,\n  TVariables extends OperationVariables = OperationVariables,\n  TCache extends ApolloCache = ApolloCache,\n> {\n  // TODO remove soon - this should be able to be handled by cancelling old operations before starting new ones\n  lastRequestId = 1;\n\n  private cache: TCache;\n  private queryManager: Pick<\n    QueryManager,\n    | \"getObservableQueries\"\n    | \"refetchQueries\"\n    | \"getDocumentInfo\"\n    | \"broadcastQueries\"\n    | \"incrementalHandler\"\n  >;\n  public readonly id: string;\n  private readonly observableQuery?: ObservableQuery<any, any>;\n  private incremental?: Incremental.IncrementalRequest<\n    Record<string, unknown>,\n    DataValue.Complete<TData> | DataValue.Streaming<TData>\n  >;\n\n  constructor(\n    queryManager: QueryManager,\n    observableQuery?: ObservableQuery<any, any>\n  ) {\n    const cache = (this.cache = queryManager.cache as TCache);\n    const id = (queryInfoIds.get(queryManager) || 0) + 1;\n    queryInfoIds.set(queryManager, id);\n    this.id = id + \"\";\n    this.observableQuery = observableQuery;\n    this.queryManager = queryManager;\n\n    // Track how often cache.evict is called, since we want eviction to\n    // override the feud-stopping logic in the markQueryResult method, by\n    // causing shouldWrite to return true. Wrapping the cache.evict method\n    // is a bit of a hack, but it saves us from having to make eviction\n    // counting an official part of the ApolloCache API.\n    if (!destructiveMethodCounts.has(cache)) {\n      destructiveMethodCounts.set(cache, 0);\n      wrapDestructiveCacheMethod(cache, \"evict\");\n      wrapDestructiveCacheMethod(cache, \"modify\");\n      wrapDestructiveCacheMethod(cache, \"reset\");\n    }\n  }\n\n  /**\n   * @internal\n   * For feud-preventing behaviour, `lastWrite` should be shared by all `QueryInfo` instances of an `ObservableQuery`.\n   * In the case of a standalone `QueryInfo`, we will keep a local version.\n   */\n  public _lastWrite?: LastWrite;\n  private get lastWrite(): LastWrite | undefined {\n    return (this.observableQuery || this)._lastWrite as LastWrite | undefined;\n  }\n  private set lastWrite(value: LastWrite | undefined) {\n    (this.observableQuery || this)._lastWrite = value;\n  }\n\n  public resetLastWrite() {\n    this.lastWrite = void 0;\n  }\n\n  private shouldWrite(\n    result: FormattedExecutionResult<any>,\n    variables: ApolloClient.WatchQueryOptions[\"variables\"]\n  ) {\n    const { lastWrite } = this;\n    return !(\n      lastWrite &&\n      // If cache.evict has been called since the last time we wrote this\n      // data into the cache, there's a chance writing this result into\n      // the cache will repair what was evicted.\n      lastWrite.dmCount === destructiveMethodCounts.get(this.cache) &&\n      equal(variables, lastWrite.variables) &&\n      equal(result.data, lastWrite.result.data)\n    );\n  }\n\n  get hasNext() {\n    return this.incremental ? this.incremental.hasNext : false;\n  }\n\n  private maybeHandleIncrementalResult(\n    cacheData: TData | DeepPartial<TData> | undefined | null,\n    incoming: ApolloLink.Result<TData>,\n    query: DocumentNode\n  ): FormattedExecutionResult<\n    DataValue.Complete<TData> | DataValue.Streaming<TData>\n  > {\n    const { incrementalHandler } = this.queryManager;\n\n    if (incrementalHandler.isIncrementalResult(incoming)) {\n      this.incremental ||= incrementalHandler.startRequest<\n        TData & Record<string, unknown>\n      >({\n        query,\n      }) as Incremental.IncrementalRequest<\n        Record<string, unknown>,\n        DataValue.Complete<TData> | DataValue.Streaming<TData>\n      >;\n\n      return this.incremental.handle(cacheData, incoming);\n    }\n    return incoming;\n  }\n\n  public markQueryResult(\n    incoming: ApolloLink.Result<TData>,\n    {\n      document: query,\n      variables,\n      errorPolicy,\n      cacheWriteBehavior,\n    }: OperationInfo<TData, TVariables>\n  ): FormattedExecutionResult<\n    DataValue.Complete<TData> | DataValue.Streaming<TData>\n  > {\n    const diffOptions = {\n      query,\n      variables,\n      returnPartialData: true,\n      optimistic: true,\n    };\n\n    // Cancel the pending notify timeout (if it exists) to prevent extraneous network\n    // requests. To allow future notify timeouts, diff and dirty are reset as well.\n    this.observableQuery?.[\"resetNotifications\"]();\n\n    const skipCache = cacheWriteBehavior === CacheWriteBehavior.FORBID;\n    const lastDiff =\n      skipCache ? undefined : this.cache.diff<TData>(diffOptions);\n\n    let result = this.maybeHandleIncrementalResult(\n      lastDiff?.result,\n      incoming,\n      query\n    );\n    if (skipCache) {\n      return result;\n    }\n\n    if (shouldWriteResult(result, errorPolicy)) {\n      // Using a transaction here so we have a chance to read the result\n      // back from the cache before the watch callback fires as a result\n      // of writeQuery, so we can store the new diff quietly and ignore\n      // it when we receive it redundantly from the watch callback.\n      this.cache.batch({\n        onWatchUpdated: (\n          // all additional options on ObservableQuery.CacheWatchOptions are\n          // optional so we can use the type here\n          watch: ObservableQuery.CacheWatchOptions,\n          diff\n        ) => {\n          if (watch.watcher === this.observableQuery) {\n            // see comment on `lastOwnDiff` for explanation\n            watch.lastOwnDiff = diff;\n          }\n        },\n        update: (cache) => {\n          if (this.shouldWrite(result, variables)) {\n            cache.writeQuery({\n              query,\n              data: result.data as Unmasked<any>,\n              variables,\n              overwrite: cacheWriteBehavior === CacheWriteBehavior.OVERWRITE,\n            });\n\n            this.lastWrite = {\n              result,\n              variables,\n              dmCount: destructiveMethodCounts.get(this.cache),\n            };\n          } else {\n            // If result is the same as the last result we received from\n            // the network (and the variables match too), avoid writing\n            // result into the cache again. The wisdom of skipping this\n            // cache write is far from obvious, since any cache write\n            // could be the one that puts the cache back into a desired\n            // state, fixing corruption or missing data. However, if we\n            // always write every network result into the cache, we enable\n            // feuds between queries competing to update the same data in\n            // incompatible ways, which can lead to an endless cycle of\n            // cache broadcasts and useless network requests. As with any\n            // feud, eventually one side must step back from the brink,\n            // letting the other side(s) have the last word(s). There may\n            // be other points where we could break this cycle, such as\n            // silencing the broadcast for cache.writeQuery (not a good\n            // idea, since it just delays the feud a bit) or somehow\n            // avoiding the network request that just happened (also bad,\n            // because the server could return useful new data). All\n            // options considered, skipping this cache write seems to be\n            // the least damaging place to break the cycle, because it\n            // reflects the intuition that we recently wrote this exact\n            // result into the cache, so the cache *should* already/still\n            // contain this data. If some other query has clobbered that\n            // data in the meantime, that's too bad, but there will be no\n            // winners if every query blindly reverts to its own version\n            // of the data. This approach also gives the network a chance\n            // to return new data, which will be written into the cache as\n            // usual, notifying only those queries that are directly\n            // affected by the cache updates, as usual. In the future, an\n            // even more sophisticated cache could perhaps prevent or\n            // mitigate the clobbering somehow, but that would make this\n            // particular cache write even less important, and thus\n            // skipping it would be even safer than it is today.\n            if (lastDiff && lastDiff.complete) {\n              // Reuse data from the last good (complete) diff that we\n              // received, when possible.\n              result = { ...result, data: lastDiff.result };\n              return;\n            }\n            // If the previous this.diff was incomplete, fall through to\n            // re-reading the latest data with cache.diff, below.\n          }\n\n          const diff = cache.diff<TData>(diffOptions);\n\n          // If we're allowed to write to the cache, and we can read a\n          // complete result from the cache, update result.data to be the\n          // result from the cache, rather than the raw network result.\n          // Set without setDiff to avoid triggering a notify call, since\n          // we have other ways of notifying for this result.\n          if (diff.complete) {\n            result = { ...result, data: diff.result };\n          }\n        },\n      });\n    } else {\n      this.lastWrite = void 0;\n    }\n\n    return result;\n  }\n\n  public markMutationResult(\n    incoming: ApolloLink.Result<TData>,\n    mutation: OperationInfo<\n      TData,\n      TVariables,\n      CacheWriteBehavior.FORBID | CacheWriteBehavior.MERGE\n    > & {\n      context?: DefaultContext;\n      updateQueries: UpdateQueries<TData>;\n      update?: MutationUpdaterFunction<TData, TVariables, TCache>;\n      awaitRefetchQueries?: boolean;\n      refetchQueries?:\n        | ((\n            result: NormalizedExecutionResult<Unmasked<TData>>\n          ) => InternalRefetchQueriesInclude)\n        | InternalRefetchQueriesInclude;\n      removeOptimistic?: string;\n      onQueryUpdated?: OnQueryUpdated<any>;\n      keepRootFields?: boolean;\n    },\n    cache = this.cache\n  ): Promise<\n    FormattedExecutionResult<\n      DataValue.Complete<TData> | DataValue.Streaming<TData>\n    >\n  > {\n    const cacheWrites: Cache.WriteOptions[] = [];\n    const skipCache = mutation.cacheWriteBehavior === CacheWriteBehavior.FORBID;\n\n    let result = this.maybeHandleIncrementalResult(\n      skipCache ? undefined : (\n        cache.diff<TData>({\n          id: \"ROOT_MUTATION\",\n          // The cache complains if passed a mutation where it expects a\n          // query, so we transform mutations and subscriptions to queries\n          // (only once, thanks to this.transformCache).\n          query: this.queryManager.getDocumentInfo(mutation.document).asQuery,\n          variables: mutation.variables,\n          optimistic: false,\n          returnPartialData: true,\n        }).result\n      ),\n      incoming,\n      mutation.document\n    );\n\n    if (mutation.errorPolicy === \"ignore\") {\n      result = { ...result, errors: [] };\n    }\n\n    if (graphQLResultHasError(result) && mutation.errorPolicy === \"none\") {\n      return Promise.resolve(result);\n    }\n\n    const getResultWithDataState = () =>\n      ({\n        ...result,\n        dataState: this.hasNext ? \"streaming\" : \"complete\",\n      }) as NormalizedExecutionResult<Unmasked<TData>>;\n\n    if (!skipCache && shouldWriteResult(result, mutation.errorPolicy)) {\n      cacheWrites.push({\n        result: result.data,\n        dataId: \"ROOT_MUTATION\",\n        query: mutation.document,\n        variables: mutation.variables,\n      });\n\n      const { updateQueries } = mutation;\n      if (updateQueries) {\n        this.queryManager\n          .getObservableQueries(\"all\")\n          .forEach((observableQuery) => {\n            const queryName = observableQuery && observableQuery.queryName;\n            if (\n              !queryName ||\n              !Object.hasOwnProperty.call(updateQueries, queryName)\n            ) {\n              return;\n            }\n            const updater = updateQueries[queryName];\n            const { query: document, variables } = observableQuery;\n\n            // Read the current query result from the store.\n            const { result: currentQueryResult, complete } =\n              observableQuery.getCacheDiff({ optimistic: false });\n\n            if (complete && currentQueryResult) {\n              // Run our reducer using the current query result and the mutation result.\n              const nextQueryResult = (updater as MutationQueryReducer<any>)(\n                currentQueryResult,\n                {\n                  mutationResult: getResultWithDataState(),\n                  queryName: (document && getOperationName(document)) || void 0,\n                  queryVariables: variables!,\n                }\n              );\n\n              // Write the modified result back into the store if we got a new result.\n              if (nextQueryResult) {\n                cacheWrites.push({\n                  result: nextQueryResult,\n                  dataId: \"ROOT_QUERY\",\n                  query: document!,\n                  variables,\n                });\n              }\n            }\n          });\n      }\n    }\n\n    let refetchQueries = mutation.refetchQueries;\n    if (typeof refetchQueries === \"function\") {\n      refetchQueries = refetchQueries(getResultWithDataState());\n    }\n\n    if (\n      cacheWrites.length > 0 ||\n      (refetchQueries || \"\").length > 0 ||\n      mutation.update ||\n      mutation.onQueryUpdated ||\n      mutation.removeOptimistic\n    ) {\n      const results: any[] = [];\n\n      this.queryManager\n        .refetchQueries({\n          updateCache: (cache) => {\n            if (!skipCache) {\n              cacheWrites.forEach((write) => cache.write(write));\n            }\n\n            // If the mutation has some writes associated with it then we need to\n            // apply those writes to the store by running this reducer again with\n            // a write action.\n            const { update } = mutation;\n            // Determine whether result is a SingleExecutionResult,\n            // or the final ExecutionPatchResult.\n\n            if (update) {\n              if (!skipCache) {\n                // Re-read the ROOT_MUTATION data we just wrote into the cache\n                // (the first cache.write call in the cacheWrites.forEach loop\n                // above), so field read functions have a chance to run for\n                // fields within mutation result objects.\n                const diff = cache.diff<TData>({\n                  id: \"ROOT_MUTATION\",\n                  // The cache complains if passed a mutation where it expects a\n                  // query, so we transform mutations and subscriptions to queries\n                  // (only once, thanks to this.transformCache).\n                  query: this.queryManager.getDocumentInfo(mutation.document)\n                    .asQuery,\n                  variables: mutation.variables,\n                  optimistic: false,\n                  returnPartialData: true,\n                });\n\n                if (diff.complete) {\n                  result = {\n                    ...result,\n                    data: diff.result,\n                  };\n                }\n              }\n\n              // If we've received the whole response, call the update function.\n              if (!this.hasNext) {\n                update(\n                  cache as TCache,\n                  result as FormattedExecutionResult<Unmasked<TData>>,\n                  {\n                    context: mutation.context,\n                    variables: mutation.variables,\n                  }\n                );\n              }\n            }\n\n            // TODO Do this with cache.evict({ id: 'ROOT_MUTATION' }) but make it\n            // shallow to allow rolling back optimistic evictions.\n            if (!skipCache && !mutation.keepRootFields && !this.hasNext) {\n              cache.modify({\n                id: \"ROOT_MUTATION\",\n                fields(value, { fieldName, DELETE }) {\n                  return fieldName === \"__typename\" ? value : DELETE;\n                },\n              });\n            }\n          },\n\n          include: refetchQueries,\n\n          // Write the final mutation.result to the root layer of the cache.\n          optimistic: false,\n\n          // Remove the corresponding optimistic layer at the same time as we\n          // write the final non-optimistic result.\n          removeOptimistic: mutation.removeOptimistic,\n\n          // Let the caller of client.mutate optionally determine the refetching\n          // behavior for watched queries after the mutation.update function runs.\n          // If no onQueryUpdated function was provided for this mutation, pass\n          // null instead of undefined to disable the default refetching behavior.\n          onQueryUpdated: mutation.onQueryUpdated || null,\n        })\n        .forEach((result) => results.push(result));\n\n      if (mutation.awaitRefetchQueries || mutation.onQueryUpdated) {\n        // Returning a promise here makes the mutation await that promise, so we\n        // include results in that promise's work if awaitRefetchQueries or an\n        // onQueryUpdated function was specified.\n        return Promise.all(results).then(() => result);\n      }\n    }\n\n    return Promise.resolve(result);\n  }\n\n  public markMutationOptimistic(\n    optimisticResponse: any,\n    mutation: OperationInfo<\n      TData,\n      TVariables,\n      CacheWriteBehavior.FORBID | CacheWriteBehavior.MERGE\n    > & {\n      context?: DefaultContext;\n      updateQueries: UpdateQueries<TData>;\n      update?: MutationUpdaterFunction<TData, TVariables, TCache>;\n      keepRootFields?: boolean;\n    }\n  ) {\n    const data =\n      typeof optimisticResponse === \"function\" ?\n        optimisticResponse(mutation.variables, { IGNORE })\n      : optimisticResponse;\n\n    if (data === IGNORE) {\n      return false;\n    }\n\n    this.cache.recordOptimisticTransaction((cache) => {\n      try {\n        this.markMutationResult({ data }, mutation, cache as TCache);\n      } catch (error) {\n        invariant.error(error);\n      }\n    }, this.id);\n\n    return true;\n  }\n\n  public markSubscriptionResult(\n    result: FormattedExecutionResult<TData>,\n    {\n      document,\n      variables,\n      errorPolicy,\n      cacheWriteBehavior,\n    }: OperationInfo<\n      TData,\n      TVariables,\n      CacheWriteBehavior.FORBID | CacheWriteBehavior.MERGE\n    >\n  ) {\n    if (cacheWriteBehavior !== CacheWriteBehavior.FORBID) {\n      if (shouldWriteResult(result, errorPolicy)) {\n        this.cache.write({\n          query: document,\n          result: result.data as any,\n          dataId: \"ROOT_SUBSCRIPTION\",\n          variables: variables,\n        });\n      }\n\n      this.queryManager.broadcastQueries();\n    }\n  }\n}\n\nfunction shouldWriteResult<T>(\n  result: FormattedExecutionResult<T>,\n  errorPolicy: ErrorPolicy = \"none\"\n) {\n  const ignoreErrors = errorPolicy === \"ignore\" || errorPolicy === \"all\";\n  let writeWithErrors = !graphQLResultHasError(result);\n  if (!writeWithErrors && ignoreErrors && result.data) {\n    writeWithErrors = true;\n  }\n  return writeWithErrors;\n}\n"],"mappings":"AAAA,SAASA,KAAT,QAAsB,eAAe;AASrC,SACEC,gBAAgB,EAChBC,qBAAqB,QAChB,mCAAmC;AAC1C,SAASC,SAAT,QAA0B,oCAAoC;AAwB9D,MAAMC,MAAN,GAAe,CAAf,CAAmC;AAcnC,MAAMC,uBAAN,GAAgC,IAAIC,OAAO,CAA3C,CAAkE;AAalE,SAASC,0BAA0BA,CACjCC,KAAkB,EAClBC,UAAwC,EAF1C;EAIE,MAAMC,QAAR,GAAmBF,KAAK,CAACC,UAAU,CAAC;EAClC,IAAI,OAAOC,QAAb,KAA0B,UAAU,EAAE;IAClC;IACAF,KAAK,CAACC,UAAU,IAAI,YAAxB;MACMJ,uBAAuB,CAACM,GAAG,CACzBH,KAAK;MACL;MACA;MACA;MACA;MACA,CAACH,uBAAuB,CAACO,GAAG,CAACJ,KAAK,IAAK,CAAC,IAAI,IAAI,CACjD;MACD;MACA,OAAOE,QAAQ,CAACG,KAAK,CAAC,IAAI,EAAEC,SAAS,CAAC;IACxC,CAAC;EACH;AACF;AAEA,MAAMC,YAAN,GAAqB,IAAIT,OAAO,CAAhC,CAAwD;AAExD;AACA;AACA;AACA;AACA;AACA,aAAaU,SAAb;EAKE;EACAC,aAAF,GAAkB,CAAC;EAETT,KAAK;EACLU,YAAY;EAQJC,EAAE;EACDC,eAAe;EACxBC,WAAW;EAKnBC,WAAFA,CACIJ,YAA0B,EAC1BE,eAA2C,EAF/C;IAII,MAAMZ,KAAV,GAAmB,IAAI,CAACA,KAAxB,GAAgCU,YAAY,CAACV,KAAgB;IACzD,MAAMW,EAAV,GAAe,CAACJ,YAAY,CAACH,GAAG,CAACM,YAAY,KAAK,CAAC,IAAI,CAAC;IACpDH,YAAY,CAACJ,GAAG,CAACO,YAAY,EAAEC,EAAE,CAAC;IAClC,IAAI,CAACA,EAAT,GAAcA,EAAd,GAAmB,EAAE;IACjB,IAAI,CAACC,eAAT,GAA2BA,eAAe;IACtC,IAAI,CAACF,YAAT,GAAwBA,YAAY;IAEhC;IACA;IACA;IACA;IACA;IACA,IAAI,CAACb,uBAAuB,CAACkB,GAAG,CAACf,KAAK,CAAC,EAAE;MACvCH,uBAAuB,CAACM,GAAG,CAACH,KAAK,EAAE,CAAC,CAAC;MACrCD,0BAA0B,CAACC,KAAK,EAAE,OAAO,CAAC;MAC1CD,0BAA0B,CAACC,KAAK,EAAE,QAAQ,CAAC;MAC3CD,0BAA0B,CAACC,KAAK,EAAE,OAAO,CAAC;IAC5C;EACF;;;;;;;;EAOOgB,UAAU;EACjB,IAAYC,SAASA,CAAA,EAAvB;IACI,OAAO,CAAC,IAAI,CAACL,eAAjB,IAAoC,IAAI,EAAEI,UAAmC;EAC3E;EACA,IAAYC,SAASA,CAACC,KAA4B,EAApD;IACI,CAAC,IAAI,CAACN,eAAV,IAA6B,IAAI,EAAEI,UAAnC,GAAgDE,KAAK;EACnD;EAEOC,cAAcA,CAAA,EAAvB;IACI,IAAI,CAACF,SAAT,GAAqB,KAAK,CAAC;EACzB;EAEQG,WAAWA,CACjBC,MAAqC,EACrCC,SAAsD,EAF1D;IAII,MAAM;MAAEL;IAAZ,IAA0B,IAAI;IAC1B,OAAO,EACLA,SADN;IAEM;IACA;IACA;IACAA,SAAS,CAACM,OAAhB,KAA4B1B,uBAAuB,CAACO,GAAG,CAAC,IAAI,CAACJ,KAAK,KAC5DR,KAAK,CAAC8B,SAAS,EAAEL,SAAS,CAACK,SAAS,KACpC9B,KAAK,CAAC6B,MAAM,CAACG,IAAI,EAAEP,SAAS,CAACI,MAAM,CAACG,IAAI,CAAC,CAC1C;EACH;EAEA,IAAIC,OAAOA,CAAA,EAAb;IACI,OAAO,IAAI,CAACZ,WAAhB,GAA8B,IAAI,CAACA,WAAW,CAACY,OAA/C,GAAyD,KAAK;EAC5D;EAEQC,4BAA4BA,CAClCC,SAAwD,EACxDC,QAAkC,EAClCC,KAAmB,EAHvB;IAOI,MAAM;MAAEC;IAAZ,IAAmC,IAAI,CAACpB,YAAY;IAEhD,IAAIoB,kBAAkB,CAACC,mBAAmB,CAACH,QAAQ,CAAC,EAAE;MACpD,IAAI,CAACf,WAAX,KAA2BiB,kBAAkB,CAACE,YAAY,CAElD;QACAH;MACR,CAAO,CAGA;MAED,OAAO,IAAI,CAAChB,WAAW,CAACoB,MAAM,CAACN,SAAS,EAAEC,QAAQ,CAAC;IACrD;IACA,OAAOA,QAAQ;EACjB;EAEOM,eAAeA,CACpBN,QAAkC,EAClC;IACEO,QAAQ,EAAEN,KAAK;IACfP,SAAS;IACTc,WAAW;IACXC;EANN,CAOuC,EAPvC;IAWI,MAAMC,WAAV,GAAwB;MAClBT,KAAK;MACLP,SAAS;MACTiB,iBAAiB,EAAE,IAAI;MACvBC,UAAU,EAAE;IAClB,CAAK;IAED;IACA;IACA,IAAI,CAAC5B,eAAe,GAAG,oBAAoB,CAAC,CAAhD,CAAkD;IAE9C,MAAM6B,SAAV,GAAsBJ,kBAAtB;IACI,MAAMK,QAAV,GACMD,SADN,GACkBE,SADlB,GAC8B,IAAI,CAAC3C,KAAK,CAAC4C,IAAI,CAAQN,WAAW,CAAC;IAE7D,IAAIjB,MAAR,GAAiB,IAAI,CAACK,4BAA4B,CAC5CgB,QAAQ,EAAErB,MAAM,EAChBO,QAAQ,EACRC,KAAK,CACN;IACD,IAAIY,SAAS,EAAE;MACb,OAAOpB,MAAM;IACf;IAEA,IAAIwB,iBAAiB,CAACxB,MAAM,EAAEe,WAAW,CAAC,EAAE;MAC1C;MACA;MACA;MACA;MACA,IAAI,CAACpC,KAAK,CAAC8C,KAAK,CAAC;QACfC,cAAc,EAAEA;QACd;QACA;QACAC,KAAwC,EACxCJ,IAAI,KADd;UAGU,IAAII,KAAK,CAACC,OAApB,KAAgC,IAAI,CAACrC,eAAe,EAAE;YAC1C;YACAoC,KAAK,CAACE,WAAlB,GAAgCN,IAAI;UAC1B;QACF,CAAC;QACDO,MAAM,EAAGnD,KAAK,IAAtB;UACU,IAAI,IAAI,CAACoB,WAAW,CAACC,MAAM,EAAEC,SAAS,CAAC,EAAE;YACvCtB,KAAK,CAACoD,UAAU,CAAC;cACfvB,KAAK;cACLL,IAAI,EAAEH,MAAM,CAACG,IAAqB;cAClCF,SAAS;cACT+B,SAAS,EAAEhB,kBAAzB;YACA,CAAa,CAAC;YAEF,IAAI,CAACpB,SAAjB,GAA6B;cACfI,MAAM;cACNC,SAAS;cACTC,OAAO,EAAE1B,uBAAuB,CAACO,GAAG,CAAC,IAAI,CAACJ,KAAK;YAC7D,CAAa;UACH,OAAO;YACL;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA,IAAI0C,QAAhB,IAA4BA,QAAQ,CAACY,QAAQ,EAAE;cACjC;cACA;cACAjC,MAAd,GAAuB;gBAAE,GAAGA,MAAM;gBAAEG,IAAI,EAAEkB,QAAQ,CAACrB;cAAnD,CAA2D;cAC7C;YACF;YACA;YACA;UACF;UAEA,MAAMuB,IAAhB,GAAuB5C,KAAK,CAAC4C,IAAI,CAAQN,WAAW,CAAC;UAE3C;UACA;UACA;UACA;UACA;UACA,IAAIM,IAAI,CAACU,QAAQ,EAAE;YACjBjC,MAAZ,GAAqB;cAAE,GAAGA,MAAM;cAAEG,IAAI,EAAEoB,IAAI,CAACvB;YAA7C,CAAqD;UAC3C;QACF;MACR,CAAO,CAAC;IACJ,OAAO;MACL,IAAI,CAACJ,SAAX,GAAuB,KAAK,CAAC;IACzB;IAEA,OAAOI,MAAM;EACf;EAEOkC,kBAAkBA,CACvB3B,QAAkC,EAClC4B,QAiBC,EACDxD,KApBJ,GAoBY,IAAI,CAACA,KAAK,EApBtB;IA0BI,MAAMyD,WAAV,GAA8C,EAAE;IAC5C,MAAMhB,SAAV,GAAsBe,QAAQ,CAACnB,kBAA/B;IAEI,IAAIhB,MAAR,GAAiB,IAAI,CAACK,4BAA4B,CAC5Ce,SADN,GACkBE,SADlB,GAEQ3C,KAAK,CAAC4C,IAAI,CAAQ;MAChBjC,EAAE,EAAE,eAAe;MACnB;MACA;MACA;MACAkB,KAAK,EAAE,IAAI,CAACnB,YAAY,CAACgD,eAAe,CAACF,QAAQ,CAACrB,QAAQ,CAAC,CAACwB,OAAO;MACnErC,SAAS,EAAEkC,QAAQ,CAAClC,SAAS;MAC7BkB,UAAU,EAAE,KAAK;MACjBD,iBAAiB,EAAE;IAC7B,CAAS,CAAC,CAAClB,MACJ,EACDO,QAAQ,EACR4B,QAAQ,CAACrB,QAAQ,CAClB;IAED,IAAIqB,QAAQ,CAACpB,WAAjB,KAAiC,QAAQ,EAAE;MACrCf,MAAN,GAAe;QAAE,GAAGA,MAAM;QAAEuC,MAAM,EAAE;MAApC,CAAwC;IACpC;IAEA,IAAIlE,qBAAqB,CAAC2B,MAAM,KAAKmC,QAAQ,CAACpB,WAAlD,KAAkE,MAAM,EAAE;MACpE,OAAOyB,OAAO,CAACC,OAAO,CAACzC,MAAM,CAAC;IAChC;IAEA,MAAM0C,sBAAV,GAAmCA,CAAA,MAC5B;MACC,GAAG1C,MAAM;MACT2C,SAAS,EAAE,IAAI,CAACvC,OAAxB,GAAkC,WAAlC,GAAgD;IAChD,CAAO,CAA+C;IAElD,IAAI,CAACgB,SAAT,IAAsBI,iBAAiB,CAACxB,MAAM,EAAEmC,QAAQ,CAACpB,WAAW,CAAC,EAAE;MACjEqB,WAAW,CAACQ,IAAI,CAAC;QACf5C,MAAM,EAAEA,MAAM,CAACG,IAAI;QACnB0C,MAAM,EAAE,eAAe;QACvBrC,KAAK,EAAE2B,QAAQ,CAACrB,QAAQ;QACxBb,SAAS,EAAEkC,QAAQ,CAAClC;MAC5B,CAAO,CAAC;MAEF,MAAM;QAAE6C;MAAd,IAAgCX,QAAQ;MAClC,IAAIW,aAAa,EAAE;QACjB,IAAI,CAACzD,YAAb,CACW0D,oBAAoB,CAAC,KAAK,EAC1BC,OAAO,CAAEzD,eAAe,IAAnC;UACY,MAAM0D,SAAlB,GAA8B1D,eAA9B,IAAiDA,eAAe,CAAC0D,SAAS;UAC9D,IACE,CAACA,SADf,IAEc,CAACC,MAAM,CAACC,cAAc,CAACC,IAAI,CAACN,aAAa,EAAEG,SAAS,CAAC,EACrD;YACA;UACF;UACA,MAAMI,OAAlB,GAA4BP,aAAa,CAACG,SAAS,CAAC;UACxC,MAAM;YAAEzC,KAAK,EAAEM,QAAQ;YAAEb;UAArC,IAAmDV,eAAe;UAEtD;UACA,MAAM;YAAES,MAAM,EAAEsD,kBAAkB;YAAErB;UAAhD,IACc1C,eAAe,CAACgE,YAAY,CAAC;YAAEpC,UAAU,EAAE;UADzD,CACgE,CAAC;UAErD,IAAIc,QAAhB,IAA4BqB,kBAAkB,EAAE;YAClC;YACA,MAAME,eAApB,GAAuCH,OAAqC,CAC5DC,kBAAkB,EAClB;cACEG,cAAc,EAAEf,sBAAsB,CAAxD,CAA0D;cACxCO,SAAS,EAAGnC,QAA9B,IAA0C1C,gBAAgB,CAAC0C,QAAQ,CAAC,IAAK,KAAK,CAAC;cAC7D4C,cAAc,EAAEzD;YAClC,CAAiB,CACF;YAED;YACA,IAAIuD,eAAe,EAAE;cACnBpB,WAAW,CAACQ,IAAI,CAAC;gBACf5C,MAAM,EAAEwD,eAAe;gBACvBX,MAAM,EAAE,YAAY;gBACpBrC,KAAK,EAAEM,QAAS;gBAChBb;cAClB,CAAiB,CAAC;YACJ;UACF;QACF,CAAC,CAAC;MACN;IACF;IAEA,IAAI0D,cAAR,GAAyBxB,QAAQ,CAACwB,cAAc;IAC5C,IAAI,OAAOA,cAAf,KAAkC,UAAU,EAAE;MACxCA,cAAN,GAAuBA,cAAc,CAACjB,sBAAsB,CAA5D,CAA8D,CAAC;IAC3D;IAEA,IACEN,WAAW,CAACwB,MADlB,GAC2B,KACrB,CAACD,cAAP,IAAyB,EAAE,EAAEC,MAA7B,GAAsC,KAChCzB,QAAQ,CAACL,MAAf,IACMK,QAAQ,CAAC0B,cAAf,IACM1B,QAAQ,CAAC2B,gBAAgB,EACzB;MACA,MAAMC,OAAZ,GAA6B,EAAE;MAEzB,IAAI,CAAC1E,YAAX,CACSsE,cAAc,CAAC;QACdK,WAAW,EAAGrF,KAAK,IAA7B;UACY,IAAI,CAACyC,SAAS,EAAE;YACdgB,WAAW,CAACY,OAAO,CAAEiB,KAAK,IAAKtF,KAAK,CAACsF,KAAK,CAACA,KAAK,CAAC,CAAC;UACpD;UAEA;UACA;UACA;UACA,MAAM;YAAEnC;UAApB,IAA+BK,QAAQ;UAC3B;UACA;UAEA,IAAIL,MAAM,EAAE;YACV,IAAI,CAACV,SAAS,EAAE;cACd;cACA;cACA;cACA;cACA,MAAMG,IAAtB,GAA6B5C,KAAK,CAAC4C,IAAI,CAAQ;gBAC7BjC,EAAE,EAAE,eAAe;gBACnB;gBACA;gBACA;gBACAkB,KAAK,EAAE,IAAI,CAACnB,YAAY,CAACgD,eAAe,CAACF,QAAQ,CAACrB,QAAQ,EACvDwB,OAAO;gBACVrC,SAAS,EAAEkC,QAAQ,CAAClC,SAAS;gBAC7BkB,UAAU,EAAE,KAAK;gBACjBD,iBAAiB,EAAE;cACrC,CAAiB,CAAC;cAEF,IAAIK,IAAI,CAACU,QAAQ,EAAE;gBACjBjC,MAAlB,GAA2B;kBACP,GAAGA,MAAM;kBACTG,IAAI,EAAEoB,IAAI,CAACvB;gBAC/B,CAAmB;cACH;YACF;YAEA;YACA,IAAI,CAAC,IAAI,CAACI,OAAO,EAAE;cACjB0B,MAAM,CACJnD,KAAe,EACfqB,MAAmD,EACnD;gBACEkE,OAAO,EAAE/B,QAAQ,CAAC+B,OAAO;gBACzBjE,SAAS,EAAEkC,QAAQ,CAAClC;cACxC,CAAmB,CACF;YACH;UACF;UAEA;UACA;UACA,IAAI,CAACmB,SAAjB,IAA8B,CAACe,QAAQ,CAACgC,cAAxC,IAA0D,CAAC,IAAI,CAAC/D,OAAO,EAAE;YAC3DzB,KAAK,CAACyF,MAAM,CAAC;cACX9E,EAAE,EAAE,eAAe;cACnB+E,MAAMA,CAACxE,KAAK,EAAE;gBAAEyE,SAAS;gBAAEC;cAA3C,CAAmD,EAAnD;gBACkB,OAAOD,SAAzB,KAAuC,YAAvC,GAAsDzE,KAAtD,GAA8D0E,MAAM;cACpD;YAChB,CAAe,CAAC;UACJ;QACF,CAAC;QAEDC,OAAO,EAAEb,cAAc;QAEvB;QACAxC,UAAU,EAAE,KAAK;QAEjB;QACA;QACA2C,gBAAgB,EAAE3B,QAAQ,CAAC2B,gBAAgB;QAE3C;QACA;QACA;QACA;QACAD,cAAc,EAAE1B,QAAQ,CAAC0B,cAAnC,IAAqD;MACrD,CAAS,EACAb,OAAO,CAAEhD,MAAM,IAAK+D,OAAO,CAACnB,IAAI,CAAC5C,MAAM,CAAC,CAAC;MAE5C,IAAImC,QAAQ,CAACsC,mBAAnB,IAA0CtC,QAAQ,CAAC0B,cAAc,EAAE;QAC3D;QACA;QACA;QACA,OAAOrB,OAAO,CAACkC,GAAG,CAACX,OAAO,CAAC,CAACY,IAAI,CAAC,MAAM3E,MAAM,CAAC;MAChD;IACF;IAEA,OAAOwC,OAAO,CAACC,OAAO,CAACzC,MAAM,CAAC;EAChC;EAEO4E,sBAAsBA,CAC3BC,kBAAuB,EACvB1C,QASC,EAXL;IAaI,MAAMhC,IAAV,GACM,OAAO0E,kBADb,KACoC,UADpC,GAEQA,kBAAkB,CAAC1C,QAAQ,CAAClC,SAAS,EAAE;MAAE1B;IAAjD,CAAyD,IACjDsG,kBAAkB;IAEtB,IAAI1E,IAAR,KAAiB5B,MAAM,EAAE;MACnB,OAAO,KAAK;IACd;IAEA,IAAI,CAACI,KAAK,CAACmG,2BAA2B,CAAEnG,KAAK,IAAjD;MACM,IAAI;QACF,IAAI,CAACuD,kBAAkB,CAAC;UAAE/B;QAAlC,CAAwC,EAAEgC,QAAQ,EAAExD,KAAe,CAAC;MAC9D,EAAE,OAAOoG,KAAK,EAAE;QACdzG,SAAS,CAACyG,KAAK,CAACA,KAAK,CAAC;MACxB;IACF,CAAC,EAAE,IAAI,CAACzF,EAAE,CAAC;IAEX,OAAO,IAAI;EACb;EAEO0F,sBAAsBA,CAC3BhF,MAAuC,EACvC;IACEc,QAAQ;IACRb,SAAS;IACTc,WAAW;IACXC;EANN,CAWK,EAXL;IAaI,IAAIA,kBAAR,wCAA0D;MACpD,IAAIQ,iBAAiB,CAACxB,MAAM,EAAEe,WAAW,CAAC,EAAE;QAC1C,IAAI,CAACpC,KAAK,CAACsF,KAAK,CAAC;UACfzD,KAAK,EAAEM,QAAQ;UACfd,MAAM,EAAEA,MAAM,CAACG,IAAW;UAC1B0C,MAAM,EAAE,mBAAmB;UAC3B5C,SAAS,EAAEA;QACrB,CAAS,CAAC;MACJ;MAEA,IAAI,CAACZ,YAAY,CAAC4F,gBAAgB,CAAxC,CAA0C;IACtC;EACF;AACF;AAEA,SAASzD,iBAAiBA,CACxBxB,MAAmC,EACnCe,WAFF,GAE6B,MAAM,EAFnC;EAIE,MAAMmE,YAAR,GAAuBnE,WAAvB,KAAuC,QAAvC,IAAmDA,WAAnD,KAAmE,KAAK;EACtE,IAAIoE,eAAN,GAAwB,CAAC9G,qBAAqB,CAAC2B,MAAM,CAAC;EACpD,IAAI,CAACmF,eAAP,IAA0BD,YAA1B,IAA0ClF,MAAM,CAACG,IAAI,EAAE;IACnDgF,eAAJ,GAAsB,IAAI;EACxB;EACA,OAAOA,eAAe;AACxB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}