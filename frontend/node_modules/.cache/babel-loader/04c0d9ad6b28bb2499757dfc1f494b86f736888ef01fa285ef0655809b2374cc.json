{"ast":null,"code":"import { disableWarningsSlot } from \"@apollo/client/masking\";\nimport { isReference } from \"@apollo/client/utilities\";\nimport { __DEV__ } from \"@apollo/client/utilities/environment\";\nimport { argumentsObjectFromField, getStoreKeyName, isArray, isNonNullObject, storeKeyNameFromField, stringifyForDisplay } from \"@apollo/client/utilities/internal\";\nimport { invariant, newInvariantError } from \"@apollo/client/utilities/invariant\";\nimport { defaultDataIdFromObject, fieldNameFromStoreName, hasOwn, selectionSetMatchesResult, storeValueIsStoreObject, TypeOrFieldNameRegExp } from \"./helpers.js\";\nimport { keyArgsFnFromSpecifier, keyFieldsFnFromSpecifier } from \"./key-extractor.js\";\nimport { cacheSlot } from \"./reactiveVars.js\";\nfunction argsFromFieldSpecifier(spec) {\n  return spec.args !== void 0 ? spec.args : spec.field ? argumentsObjectFromField(spec.field, spec.variables) : null;\n}\nconst nullKeyFieldsFn = () => void 0;\nconst simpleKeyArgsFn = (_args, context) => context.fieldName;\n// These merge functions can be selected by specifying merge:true or\n// merge:false in a field policy.\nconst mergeTrueFn = (existing, incoming, {\n  mergeObjects\n}) => mergeObjects(existing, incoming);\nconst mergeFalseFn = (_, incoming) => incoming;\nexport class Policies {\n  config;\n  typePolicies = {};\n  toBeAdded = {};\n  // Map from subtype names to sets of supertype names. Note that this\n  // representation inverts the structure of possibleTypes (whose keys are\n  // supertypes and whose values are arrays of subtypes) because it tends\n  // to be much more efficient to search upwards than downwards.\n  supertypeMap = new Map();\n  // Any fuzzy subtypes specified by possibleTypes will be converted to\n  // RegExp objects and recorded here. Every key of this map can also be\n  // found in supertypeMap. In many cases this Map will be empty, which\n  // means no fuzzy subtype checking will happen in fragmentMatches.\n  fuzzySubtypes = new Map();\n  cache;\n  rootIdsByTypename = {};\n  rootTypenamesById = {};\n  usingPossibleTypes = false;\n  constructor(config) {\n    this.config = config;\n    this.config = {\n      dataIdFromObject: defaultDataIdFromObject,\n      ...config\n    };\n    this.cache = this.config.cache;\n    this.setRootTypename(\"Query\");\n    this.setRootTypename(\"Mutation\");\n    this.setRootTypename(\"Subscription\");\n    if (config.possibleTypes) {\n      this.addPossibleTypes(config.possibleTypes);\n    }\n    if (config.typePolicies) {\n      this.addTypePolicies(config.typePolicies);\n    }\n  }\n  identify(object, partialContext) {\n    const policies = this;\n    const typename = partialContext && (partialContext.typename || partialContext.storeObject?.__typename) || object.__typename;\n    // It should be possible to write root Query fields with writeFragment,\n    // using { __typename: \"Query\", ... } as the data, but it does not make\n    // sense to allow the same identification behavior for the Mutation and\n    // Subscription types, since application code should never be writing\n    // directly to (or reading directly from) those root objects.\n    if (typename === this.rootTypenamesById.ROOT_QUERY) {\n      return [\"ROOT_QUERY\"];\n    }\n    // Default context.storeObject to object if not otherwise provided.\n    const storeObject = partialContext && partialContext.storeObject || object;\n    const context = {\n      ...partialContext,\n      typename,\n      storeObject,\n      readField: partialContext && partialContext.readField || ((...args) => {\n        const options = normalizeReadFieldOptions(args, storeObject);\n        return policies.readField(options, {\n          store: policies.cache[\"data\"],\n          variables: options.variables\n        });\n      })\n    };\n    let id;\n    const policy = typename && this.getTypePolicy(typename);\n    let keyFn = policy && policy.keyFn || this.config.dataIdFromObject;\n    disableWarningsSlot.withValue(true, () => {\n      while (keyFn) {\n        const specifierOrId = keyFn({\n          ...object,\n          ...storeObject\n        }, context);\n        if (isArray(specifierOrId)) {\n          keyFn = keyFieldsFnFromSpecifier(specifierOrId);\n        } else {\n          id = specifierOrId;\n          break;\n        }\n      }\n    });\n    id = id ? String(id) : void 0;\n    return context.keyObject ? [id, context.keyObject] : [id];\n  }\n  addTypePolicies(typePolicies) {\n    Object.keys(typePolicies).forEach(typename => {\n      const {\n        queryType,\n        mutationType,\n        subscriptionType,\n        ...incoming\n      } = typePolicies[typename];\n      // Though {query,mutation,subscription}Type configurations are rare,\n      // it's important to call setRootTypename as early as possible,\n      // since these configurations should apply consistently for the\n      // entire lifetime of the cache. Also, since only one __typename can\n      // qualify as one of these root types, these three properties cannot\n      // be inherited, unlike the rest of the incoming properties. That\n      // restriction is convenient, because the purpose of this.toBeAdded\n      // is to delay the processing of type/field policies until the first\n      // time they're used, allowing policies to be added in any order as\n      // long as all relevant policies (including policies for supertypes)\n      // have been added by the time a given policy is used for the first\n      // time. In other words, since inheritance doesn't matter for these\n      // properties, there's also no need to delay their processing using\n      // the this.toBeAdded queue.\n      if (queryType) this.setRootTypename(\"Query\", typename);\n      if (mutationType) this.setRootTypename(\"Mutation\", typename);\n      if (subscriptionType) this.setRootTypename(\"Subscription\", typename);\n      if (hasOwn.call(this.toBeAdded, typename)) {\n        this.toBeAdded[typename].push(incoming);\n      } else {\n        this.toBeAdded[typename] = [incoming];\n      }\n    });\n  }\n  updateTypePolicy(typename, incoming, existingFieldPolicies) {\n    const existing = this.getTypePolicy(typename);\n    const {\n      keyFields,\n      fields\n    } = incoming;\n    function setMerge(existing, merge) {\n      existing.merge = typeof merge === \"function\" ? merge\n      // Pass merge:true as a shorthand for a merge implementation\n      // that returns options.mergeObjects(existing, incoming).\n      : merge === true ? mergeTrueFn\n      // Pass merge:false to make incoming always replace existing\n      // without any warnings about data clobbering.\n      : merge === false ? mergeFalseFn : existing.merge;\n    }\n    // Type policies can define merge functions, as an alternative to\n    // using field policies to merge child objects.\n    setMerge(existing, incoming.merge);\n    existing.keyFn =\n    // Pass false to disable normalization for this typename.\n    keyFields === false ? nullKeyFieldsFn\n    // Pass an array of strings to use those fields to compute a\n    // composite ID for objects of this typename.\n    : isArray(keyFields) ? keyFieldsFnFromSpecifier(keyFields)\n    // Pass a function to take full control over identification.\n    : typeof keyFields === \"function\" ? keyFields\n    // Leave existing.keyFn unchanged if above cases fail.\n    : existing.keyFn;\n    if (fields) {\n      Object.keys(fields).forEach(fieldName => {\n        let existing = existingFieldPolicies[fieldName];\n        // Field policy inheritance is atomic/shallow: you can't inherit a\n        // field policy and then override just its read function, since read\n        // and merge functions often need to cooperate, so changing only one\n        // of them would be a recipe for inconsistency.\n        // So here we avoid merging an inherited field policy with an updated one.\n        if (!existing || existing?.typename !== typename) {\n          existing = existingFieldPolicies[fieldName] = {\n            typename\n          };\n        }\n        const incoming = fields[fieldName];\n        if (typeof incoming === \"function\") {\n          existing.read = incoming;\n        } else {\n          const {\n            keyArgs,\n            read,\n            merge\n          } = incoming;\n          existing.keyFn =\n          // Pass false to disable argument-based differentiation of\n          // field identities.\n          keyArgs === false ? simpleKeyArgsFn\n          // Pass an array of strings to use named arguments to\n          // compute a composite identity for the field.\n          : isArray(keyArgs) ? keyArgsFnFromSpecifier(keyArgs)\n          // Pass a function to take full control over field identity.\n          : typeof keyArgs === \"function\" ? keyArgs\n          // Leave existing.keyFn unchanged if above cases fail.\n          : existing.keyFn;\n          if (typeof read === \"function\") {\n            existing.read = read;\n          }\n          setMerge(existing, merge);\n        }\n        if (existing.read && existing.merge) {\n          // If we have both a read and a merge function, assume\n          // keyArgs:false, because read and merge together can take\n          // responsibility for interpreting arguments in and out. This\n          // default assumption can always be overridden by specifying\n          // keyArgs explicitly in the FieldPolicy.\n          existing.keyFn = existing.keyFn || simpleKeyArgsFn;\n        }\n      });\n    }\n  }\n  setRootTypename(which, typename = which) {\n    const rootId = \"ROOT_\" + which.toUpperCase();\n    const old = this.rootTypenamesById[rootId];\n    if (typename !== old) {\n      invariant(!old || old === which, 99, which);\n      // First, delete any old __typename associated with this rootId from\n      // rootIdsByTypename.\n      if (old) delete this.rootIdsByTypename[old];\n      // Now make this the only __typename that maps to this rootId.\n      this.rootIdsByTypename[typename] = rootId;\n      // Finally, update the __typename associated with this rootId.\n      this.rootTypenamesById[rootId] = typename;\n    }\n  }\n  addPossibleTypes(possibleTypes) {\n    this.usingPossibleTypes = true;\n    Object.keys(possibleTypes).forEach(supertype => {\n      // Make sure all types have an entry in this.supertypeMap, even if\n      // their supertype set is empty, so we can return false immediately\n      // from policies.fragmentMatches for unknown supertypes.\n      this.getSupertypeSet(supertype, true);\n      possibleTypes[supertype].forEach(subtype => {\n        this.getSupertypeSet(subtype, true).add(supertype);\n        const match = subtype.match(TypeOrFieldNameRegExp);\n        if (!match || match[0] !== subtype) {\n          // TODO Don't interpret just any invalid typename as a RegExp.\n          this.fuzzySubtypes.set(subtype, new RegExp(subtype));\n        }\n      });\n    });\n  }\n  getTypePolicy(typename) {\n    if (!hasOwn.call(this.typePolicies, typename)) {\n      const policy = this.typePolicies[typename] = {};\n      policy.fields = {};\n      // When the TypePolicy for typename is first accessed, instead of\n      // starting with an empty policy object, inherit any properties or\n      // fields from the type policies of the supertypes of typename.\n      //\n      // Any properties or fields defined explicitly within the TypePolicy\n      // for typename will take precedence, and if there are multiple\n      // supertypes, the properties of policies whose types were added\n      // later via addPossibleTypes will take precedence over those of\n      // earlier supertypes. TODO Perhaps we should warn about these\n      // conflicts in development, and recommend defining the property\n      // explicitly in the subtype policy?\n      //\n      // Field policy inheritance is atomic/shallow: you can't inherit a\n      // field policy and then override just its read function, since read\n      // and merge functions often need to cooperate, so changing only one\n      // of them would be a recipe for inconsistency.\n      //\n      // Once the TypePolicy for typename has been accessed, its properties can\n      // still be updated directly using addTypePolicies, but future changes to\n      // inherited supertype policies will not be reflected in this subtype\n      // policy, because this code runs at most once per typename.\n      let supertypes = this.supertypeMap.get(typename);\n      if (!supertypes && this.fuzzySubtypes.size) {\n        // To make the inheritance logic work for unknown typename strings that\n        // may have fuzzy supertypes, we give this typename an empty supertype\n        // set and then populate it with any fuzzy supertypes that match.\n        supertypes = this.getSupertypeSet(typename, true);\n        // This only works for typenames that are directly matched by a fuzzy\n        // supertype. What if there is an intermediate chain of supertypes?\n        // While possible, that situation can only be solved effectively by\n        // specifying the intermediate relationships via possibleTypes, manually\n        // and in a non-fuzzy way.\n        this.fuzzySubtypes.forEach((regExp, fuzzy) => {\n          if (regExp.test(typename)) {\n            // The fuzzy parameter is just the original string version of regExp\n            // (not a valid __typename string), but we can look up the\n            // associated supertype(s) in this.supertypeMap.\n            const fuzzySupertypes = this.supertypeMap.get(fuzzy);\n            if (fuzzySupertypes) {\n              fuzzySupertypes.forEach(supertype => supertypes.add(supertype));\n            }\n          }\n        });\n      }\n      if (supertypes && supertypes.size) {\n        supertypes.forEach(supertype => {\n          const {\n            fields,\n            ...rest\n          } = this.getTypePolicy(supertype);\n          Object.assign(policy, rest);\n          Object.assign(policy.fields, fields);\n        });\n      }\n    }\n    const inbox = this.toBeAdded[typename];\n    if (inbox && inbox.length) {\n      // Merge the pending policies into this.typePolicies, in the order they\n      // were originally passed to addTypePolicy.\n      inbox.splice(0).forEach(policy => {\n        this.updateTypePolicy(typename, policy, this.typePolicies[typename].fields);\n      });\n    }\n    return this.typePolicies[typename];\n  }\n  getFieldPolicy(typename, fieldName) {\n    if (typename) {\n      return this.getTypePolicy(typename).fields[fieldName];\n    }\n  }\n  getSupertypeSet(subtype, createIfMissing) {\n    let supertypeSet = this.supertypeMap.get(subtype);\n    if (!supertypeSet && createIfMissing) {\n      this.supertypeMap.set(subtype, supertypeSet = new Set());\n    }\n    return supertypeSet;\n  }\n  fragmentMatches(fragment, typename, result, variables) {\n    if (!fragment.typeCondition) return true;\n    // If the fragment has a type condition but the object we're matching\n    // against does not have a __typename, the fragment cannot match.\n    if (!typename) return false;\n    const supertype = fragment.typeCondition.name.value;\n    // Common case: fragment type condition and __typename are the same.\n    if (typename === supertype) return true;\n    if (this.usingPossibleTypes && this.supertypeMap.has(supertype)) {\n      const typenameSupertypeSet = this.getSupertypeSet(typename, true);\n      const workQueue = [typenameSupertypeSet];\n      const maybeEnqueue = subtype => {\n        const supertypeSet = this.getSupertypeSet(subtype, false);\n        if (supertypeSet && supertypeSet.size && workQueue.indexOf(supertypeSet) < 0) {\n          workQueue.push(supertypeSet);\n        }\n      };\n      // We need to check fuzzy subtypes only if we encountered fuzzy\n      // subtype strings in addPossibleTypes, and only while writing to\n      // the cache, since that's when selectionSetMatchesResult gives a\n      // strong signal of fragment matching. The StoreReader class calls\n      // policies.fragmentMatches without passing a result object, so\n      // needToCheckFuzzySubtypes is always false while reading.\n      let needToCheckFuzzySubtypes = !!(result && this.fuzzySubtypes.size);\n      let checkingFuzzySubtypes = false;\n      // It's important to keep evaluating workQueue.length each time through\n      // the loop, because the queue can grow while we're iterating over it.\n      for (let i = 0; i < workQueue.length; ++i) {\n        const supertypeSet = workQueue[i];\n        if (supertypeSet.has(supertype)) {\n          if (!typenameSupertypeSet.has(supertype)) {\n            if (checkingFuzzySubtypes) {\n              __DEV__ && invariant.warn(100, typename, supertype);\n            }\n            // Record positive results for faster future lookup.\n            // Unfortunately, we cannot safely cache negative results,\n            // because new possibleTypes data could always be added to the\n            // Policies class.\n            typenameSupertypeSet.add(supertype);\n          }\n          return true;\n        }\n        supertypeSet.forEach(maybeEnqueue);\n        if (needToCheckFuzzySubtypes &&\n        // Start checking fuzzy subtypes only after exhausting all\n        // non-fuzzy subtypes (after the final iteration of the loop).\n        i === workQueue.length - 1 &&\n        // We could wait to compare fragment.selectionSet to result\n        // after we verify the supertype, but this check is often less\n        // expensive than that search, and we will have to do the\n        // comparison anyway whenever we find a potential match.\n        selectionSetMatchesResult(fragment.selectionSet, result, variables)) {\n          // We don't always need to check fuzzy subtypes (if no result\n          // was provided, or !this.fuzzySubtypes.size), but, when we do,\n          // we only want to check them once.\n          needToCheckFuzzySubtypes = false;\n          checkingFuzzySubtypes = true;\n          // If we find any fuzzy subtypes that match typename, extend the\n          // workQueue to search through the supertypes of those fuzzy\n          // subtypes. Otherwise the for-loop will terminate and we'll\n          // return false below.\n          this.fuzzySubtypes.forEach((regExp, fuzzyString) => {\n            const match = typename.match(regExp);\n            if (match && match[0] === typename) {\n              maybeEnqueue(fuzzyString);\n            }\n          });\n        }\n      }\n    }\n    return false;\n  }\n  hasKeyArgs(typename, fieldName) {\n    const policy = this.getFieldPolicy(typename, fieldName);\n    return !!(policy && policy.keyFn);\n  }\n  getStoreFieldName(fieldSpec) {\n    const {\n      typename,\n      fieldName\n    } = fieldSpec;\n    const policy = this.getFieldPolicy(typename, fieldName);\n    let storeFieldName;\n    let keyFn = policy && policy.keyFn;\n    if (keyFn && typename) {\n      const context = {\n        typename,\n        fieldName,\n        field: fieldSpec.field || null,\n        variables: fieldSpec.variables\n      };\n      const args = argsFromFieldSpecifier(fieldSpec);\n      while (keyFn) {\n        const specifierOrString = keyFn(args, context);\n        if (isArray(specifierOrString)) {\n          keyFn = keyArgsFnFromSpecifier(specifierOrString);\n        } else {\n          // If the custom keyFn returns a falsy value, fall back to\n          // fieldName instead.\n          storeFieldName = specifierOrString || fieldName;\n          break;\n        }\n      }\n    }\n    if (storeFieldName === void 0) {\n      storeFieldName = fieldSpec.field ? storeKeyNameFromField(fieldSpec.field, fieldSpec.variables) : getStoreKeyName(fieldName, argsFromFieldSpecifier(fieldSpec));\n    }\n    // Returning false from a keyArgs function is like configuring\n    // keyArgs: false, but more dynamic.\n    if (storeFieldName === false) {\n      return fieldName;\n    }\n    // Make sure custom field names start with the actual field.name.value\n    // of the field, so we can always figure out which properties of a\n    // StoreObject correspond to which original field names.\n    return fieldName === fieldNameFromStoreName(storeFieldName) ? storeFieldName : fieldName + \":\" + storeFieldName;\n  }\n  readField(options, context) {\n    const objectOrReference = options.from;\n    if (!objectOrReference) return;\n    const nameOrField = options.field || options.fieldName;\n    if (!nameOrField) return;\n    if (options.typename === void 0) {\n      const typename = context.store.getFieldValue(objectOrReference, \"__typename\");\n      if (typename) options.typename = typename;\n    }\n    const storeFieldName = this.getStoreFieldName(options);\n    const fieldName = fieldNameFromStoreName(storeFieldName);\n    const existing = context.store.getFieldValue(objectOrReference, storeFieldName);\n    const policy = this.getFieldPolicy(options.typename, fieldName);\n    const read = policy && policy.read;\n    if (read) {\n      const readOptions = makeFieldFunctionOptions(this, objectOrReference, options, context, context.store.getStorage(isReference(objectOrReference) ? objectOrReference.__ref : objectOrReference, storeFieldName));\n      // Call read(existing, readOptions) with cacheSlot holding this.cache.\n      return cacheSlot.withValue(this.cache, read, [existing, readOptions]);\n    }\n    return existing;\n  }\n  getReadFunction(typename, fieldName) {\n    const policy = this.getFieldPolicy(typename, fieldName);\n    return policy && policy.read;\n  }\n  getMergeFunction(parentTypename, fieldName, childTypename) {\n    let policy = this.getFieldPolicy(parentTypename, fieldName);\n    let merge = policy && policy.merge;\n    if (!merge && childTypename) {\n      policy = this.getTypePolicy(childTypename);\n      merge = policy && policy.merge;\n    }\n    return merge;\n  }\n  runMergeFunction(existing, incoming, {\n    field,\n    typename,\n    merge\n  }, context, storage) {\n    if (merge === mergeTrueFn) {\n      // Instead of going to the trouble of creating a full\n      // FieldFunctionOptions object and calling mergeTrueFn, we can\n      // simply call mergeObjects, as mergeTrueFn would.\n      return makeMergeObjectsFunction(context.store)(existing, incoming);\n    }\n    if (merge === mergeFalseFn) {\n      // Likewise for mergeFalseFn, whose implementation is even simpler.\n      return incoming;\n    }\n    // If cache.writeQuery or cache.writeFragment was called with\n    // options.overwrite set to true, we still call merge functions, but\n    // the existing data is always undefined, so the merge function will\n    // not attempt to combine the incoming data with the existing data.\n    if (context.overwrite) {\n      existing = void 0;\n    }\n    return merge(existing, incoming, makeFieldFunctionOptions(this,\n    // Unlike options.readField for read functions, we do not fall\n    // back to the current object if no foreignObjOrRef is provided,\n    // because it's not clear what the current object should be for\n    // merge functions: the (possibly undefined) existing object, or\n    // the incoming object? If you think your merge function needs\n    // to read sibling fields in order to produce a new value for\n    // the current field, you might want to rethink your strategy,\n    // because that's a recipe for making merge behavior sensitive\n    // to the order in which fields are written into the cache.\n    // However, readField(name, ref) is useful for merge functions\n    // that need to deduplicate child objects and references.\n    void 0, {\n      typename,\n      fieldName: field.name.value,\n      field,\n      variables: context.variables\n    }, context, storage || {}));\n  }\n}\nfunction makeFieldFunctionOptions(policies, objectOrReference, fieldSpec, context, storage) {\n  const storeFieldName = policies.getStoreFieldName(fieldSpec);\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const variables = fieldSpec.variables || context.variables;\n  const {\n    toReference,\n    canRead\n  } = context.store;\n  return {\n    args: argsFromFieldSpecifier(fieldSpec),\n    field: fieldSpec.field || null,\n    fieldName,\n    storeFieldName,\n    variables,\n    isReference,\n    toReference,\n    storage,\n    cache: policies.cache,\n    canRead,\n    readField(...args) {\n      return policies.readField(normalizeReadFieldOptions(args, objectOrReference, variables), context);\n    },\n    mergeObjects: makeMergeObjectsFunction(context.store)\n  };\n}\nexport function normalizeReadFieldOptions(readFieldArgs, objectOrReference, variables) {\n  const {\n    0: fieldNameOrOptions,\n    1: from,\n    length: argc\n  } = readFieldArgs;\n  let options;\n  if (typeof fieldNameOrOptions === \"string\") {\n    options = {\n      fieldName: fieldNameOrOptions,\n      // Default to objectOrReference only when no second argument was\n      // passed for the from parameter, not when undefined is explicitly\n      // passed as the second argument.\n      from: argc > 1 ? from : objectOrReference\n    };\n  } else {\n    options = {\n      ...fieldNameOrOptions\n    };\n    // Default to objectOrReference only when fieldNameOrOptions.from is\n    // actually omitted, rather than just undefined.\n    if (!hasOwn.call(options, \"from\")) {\n      options.from = objectOrReference;\n    }\n  }\n  if (__DEV__ && options.from === void 0) {\n    __DEV__ && invariant.warn(101, stringifyForDisplay(Array.from(readFieldArgs)));\n  }\n  if (void 0 === options.variables) {\n    options.variables = variables;\n  }\n  return options;\n}\nfunction makeMergeObjectsFunction(store) {\n  return function mergeObjects(existing, incoming) {\n    if (isArray(existing) || isArray(incoming)) {\n      throw newInvariantError(102);\n    }\n    // These dynamic checks are necessary because the parameters of a\n    // custom merge function can easily have the any type, so the type\n    // system cannot always enforce the StoreObject | Reference parameter\n    // types of options.mergeObjects.\n    if (isNonNullObject(existing) && isNonNullObject(incoming)) {\n      const eType = store.getFieldValue(existing, \"__typename\");\n      const iType = store.getFieldValue(incoming, \"__typename\");\n      const typesDiffer = eType && iType && eType !== iType;\n      if (typesDiffer) {\n        return incoming;\n      }\n      if (isReference(existing) && storeValueIsStoreObject(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // existing.__ref, preferring/overwriting any fields contributed by the\n        // newer incoming StoreObject.\n        store.merge(existing.__ref, incoming);\n        return existing;\n      }\n      if (storeValueIsStoreObject(existing) && isReference(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // incoming.__ref, taking fields from the older existing object only if\n        // those fields are not already present in the newer StoreObject\n        // identified by incoming.__ref.\n        store.merge(existing, incoming.__ref);\n        return incoming;\n      }\n      if (storeValueIsStoreObject(existing) && storeValueIsStoreObject(incoming)) {\n        return {\n          ...existing,\n          ...incoming\n        };\n      }\n    }\n    return incoming;\n  };\n}","map":{"version":3,"names":["disableWarningsSlot","isReference","__DEV__","argumentsObjectFromField","getStoreKeyName","isArray","isNonNullObject","storeKeyNameFromField","stringifyForDisplay","invariant","newInvariantError","defaultDataIdFromObject","fieldNameFromStoreName","hasOwn","selectionSetMatchesResult","storeValueIsStoreObject","TypeOrFieldNameRegExp","keyArgsFnFromSpecifier","keyFieldsFnFromSpecifier","cacheSlot","argsFromFieldSpecifier","spec","args","field","variables","nullKeyFieldsFn","simpleKeyArgsFn","_args","context","fieldName","mergeTrueFn","existing","incoming","mergeObjects","mergeFalseFn","_","Policies","config","typePolicies","toBeAdded","supertypeMap","Map","fuzzySubtypes","cache","rootIdsByTypename","rootTypenamesById","usingPossibleTypes","constructor","dataIdFromObject","setRootTypename","possibleTypes","addPossibleTypes","addTypePolicies","identify","object","partialContext","policies","typename","storeObject","__typename","ROOT_QUERY","readField","options","normalizeReadFieldOptions","store","id","policy","getTypePolicy","keyFn","withValue","specifierOrId","String","keyObject","Object","keys","forEach","queryType","mutationType","subscriptionType","call","push","updateTypePolicy","existingFieldPolicies","keyFields","fields","setMerge","merge","read","keyArgs","which","rootId","toUpperCase","old","supertype","getSupertypeSet","subtype","add","match","set","RegExp","supertypes","get","size","regExp","fuzzy","test","fuzzySupertypes","rest","assign","inbox","length","splice","getFieldPolicy","createIfMissing","supertypeSet","Set","fragmentMatches","fragment","result","typeCondition","name","value","has","typenameSupertypeSet","workQueue","maybeEnqueue","indexOf","needToCheckFuzzySubtypes","checkingFuzzySubtypes","i","warn","selectionSet","fuzzyString","hasKeyArgs","getStoreFieldName","fieldSpec","storeFieldName","specifierOrString","objectOrReference","from","nameOrField","getFieldValue","readOptions","makeFieldFunctionOptions","getStorage","__ref","getReadFunction","getMergeFunction","parentTypename","childTypename","runMergeFunction","storage","makeMergeObjectsFunction","overwrite","toReference","canRead","readFieldArgs","fieldNameOrOptions","argc","Array","eType","iType","typesDiffer"],"sources":["/home/saurabh-shukla/Desktop/Slack Lite/frontend/node_modules/@apollo/src/cache/inmemory/policies.ts"],"sourcesContent":["import type {\n  FieldNode,\n  FragmentDefinitionNode,\n  InlineFragmentNode,\n  SelectionSetNode,\n} from \"graphql\";\n\nimport type { OperationVariables } from \"@apollo/client\";\nimport { disableWarningsSlot } from \"@apollo/client/masking\";\nimport type {\n  Reference,\n  StoreObject,\n  StoreValue,\n} from \"@apollo/client/utilities\";\nimport { isReference } from \"@apollo/client/utilities\";\nimport { __DEV__ } from \"@apollo/client/utilities/environment\";\nimport type { FragmentMap } from \"@apollo/client/utilities/internal\";\nimport {\n  argumentsObjectFromField,\n  getStoreKeyName,\n  isArray,\n  isNonNullObject,\n  storeKeyNameFromField,\n  stringifyForDisplay,\n} from \"@apollo/client/utilities/internal\";\nimport {\n  invariant,\n  newInvariantError,\n} from \"@apollo/client/utilities/invariant\";\n\nimport type {\n  CanReadFunction,\n  FieldSpecifier,\n  ReadFieldFunction,\n  ReadFieldOptions,\n  SafeReadonly,\n  ToReferenceFunction,\n} from \"../core/types/common.js\";\n\nimport {\n  defaultDataIdFromObject,\n  fieldNameFromStoreName,\n  hasOwn,\n  selectionSetMatchesResult,\n  storeValueIsStoreObject,\n  TypeOrFieldNameRegExp,\n} from \"./helpers.js\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport {\n  keyArgsFnFromSpecifier,\n  keyFieldsFnFromSpecifier,\n} from \"./key-extractor.js\";\nimport { cacheSlot } from \"./reactiveVars.js\";\nimport type {\n  IdGetter,\n  MergeInfo,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from \"./types.js\";\nimport type { WriteContext } from \"./writeToStore.js\";\n\nexport type TypePolicies = {\n  [__typename: string]: TypePolicy;\n};\n\n// TypeScript 3.7 will allow recursive type aliases, so this should work:\n// type KeySpecifier = (string | KeySpecifier)[]\nexport type KeySpecifier = ReadonlyArray<string | KeySpecifier>;\n\nexport type KeyFieldsContext = {\n  // The __typename of the incoming object, even if the __typename field was\n  // aliased to another name in the raw result object. May be undefined when\n  // dataIdFromObject is called for objects without __typename fields.\n  typename: string | undefined;\n\n  // The object to be identified, after processing to remove aliases and\n  // normalize identifiable child objects with references.\n  storeObject: StoreObject;\n\n  // Handy tool for reading additional fields from context.storeObject, either\n  // readField(\"fieldName\") to read storeObject[fieldName], or readField(\"name\",\n  // objectOrReference) to read from another object or Reference. If you read a\n  // field with a read function, that function will be invoked.\n  readField: ReadFieldFunction;\n\n  // If you are writing a custom keyFields function, and you plan to use the raw\n  // result object passed as the first argument, you may also need access to the\n  // selection set and available fragments for this object, just in case any\n  // fields have aliases. Since this logic is tricky to get right, and these\n  // context properties are not even always provided (for example, they are\n  // omitted when calling cache.identify(object), where object is assumed to be\n  // a StoreObject), we recommend you use context.storeObject (which has already\n  // been de-aliased) and context.readField (which can read from references as\n  // well as objects) instead of the raw result object in your keyFields\n  // functions, or just rely on the internal implementation of keyFields:[...]\n  // syntax to get these details right for you.\n  selectionSet?: SelectionSetNode;\n  fragmentMap?: FragmentMap;\n\n  // Internal. May be set by the KeyFieldsFunction to report fields that were\n  // involved in computing the ID. Never passed in by the caller.\n  keyObject?: Record<string, any>;\n};\n\nexport type KeyFieldsFunction = (\n  object: Readonly<StoreObject>,\n  context: KeyFieldsContext\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\ntype KeyFieldsResult = Exclude<ReturnType<KeyFieldsFunction>, KeySpecifier>;\n\n// TODO Should TypePolicy be a generic type, with a TObject or TEntity\n// type parameter?\nexport type TypePolicy = {\n  // Allows defining the primary key fields for this type, either using an\n  // array of field names or a function that returns an arbitrary string.\n  keyFields?: KeySpecifier | KeyFieldsFunction | false;\n\n  // Allows defining a merge function (or merge:true/false shorthand) to\n  // be used for merging objects of this type wherever they appear, unless\n  // the parent field also defines a merge function/boolean (that is,\n  // parent field merge functions take precedence over type policy merge\n  // functions). In many cases, defining merge:true for a given type\n  // policy can save you from specifying merge:true for all the field\n  // policies where that type might be encountered.\n  merge?: FieldMergeFunction | boolean;\n\n  // In the rare event that your schema happens to use a different\n  // __typename for the root Query, Mutation, and/or Schema types, you can\n  // express your deviant preferences by enabling one of these options.\n  queryType?: true;\n  mutationType?: true;\n  subscriptionType?: true;\n\n  fields?: {\n    [fieldName: string]: FieldPolicy<any> | FieldReadFunction<any>;\n  };\n};\n\nexport type KeyArgsFunction = (\n  args: Record<string, any> | null,\n  context: {\n    typename: string;\n    fieldName: string;\n    field: FieldNode | null;\n    variables?: Record<string, any>;\n  }\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\nexport type FieldPolicy<\n  // The internal representation used to store the field's data in the\n  // cache. Must be JSON-serializable if you plan to serialize the result\n  // of cache.extract() using JSON.\n  TExisting = any,\n  // The type of the incoming parameter passed to the merge function,\n  // typically matching the GraphQL response format, but with Reference\n  // objects substituted for any identifiable child objects. Often the\n  // same as TExisting, but not necessarily.\n  TIncoming = TExisting,\n  // The type that the read function actually returns, using TExisting\n  // data and options.args as input. Usually the same as TIncoming.\n  TReadResult = TIncoming,\n  // Allows FieldFunctionOptions definition to be overwritten by the\n  // developer\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = {\n  keyArgs?: KeySpecifier | KeyArgsFunction | false;\n  read?: FieldReadFunction<TExisting, TReadResult, TOptions>;\n  merge?: FieldMergeFunction<TExisting, TIncoming, TOptions> | boolean;\n};\n\nexport type StorageType = Record<string, any>;\n\nfunction argsFromFieldSpecifier(spec: FieldSpecifier) {\n  return (\n    spec.args !== void 0 ? spec.args\n    : spec.field ? argumentsObjectFromField(spec.field, spec.variables)\n    : null\n  );\n}\n\nexport interface FieldFunctionOptions<\n  TArgs = Record<string, any>,\n  TVariables extends OperationVariables = Record<string, any>,\n> {\n  args: TArgs | null;\n\n  // The name of the field, equal to options.field.name.value when\n  // options.field is available. Useful if you reuse the same function for\n  // multiple fields, and you need to know which field you're currently\n  // processing. Always a string, even when options.field is null.\n  fieldName: string;\n\n  // The full field key used internally, including serialized key arguments.\n  storeFieldName: string;\n\n  // The FieldNode object used to read this field. Useful if you need to\n  // know about other attributes of the field, such as its directives. This\n  // option will be null when a string was passed to options.readField.\n  field: FieldNode | null;\n\n  variables?: TVariables;\n\n  // Utilities for dealing with { __ref } objects.\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n\n  // A handy place to put field-specific data that you want to survive\n  // across multiple read function calls. Useful for field-level caching,\n  // if your read function does any expensive work.\n  storage: StorageType;\n\n  cache: InMemoryCache;\n\n  // Helper function for reading other fields within the current object.\n  // If a foreign object or reference is provided, the field will be read\n  // from that object instead of the current object, so this function can\n  // be used (together with isReference) to examine the cache outside the\n  // current object. If a FieldNode is passed instead of a string, and\n  // that FieldNode has arguments, the same options.variables will be used\n  // to compute the argument values. Note that this function will invoke\n  // custom read functions for other fields, if defined. Always returns\n  // immutable data (enforced with Object.freeze in development).\n  readField: ReadFieldFunction;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  canRead: CanReadFunction;\n\n  // Instead of just merging objects with { ...existing, ...incoming }, this\n  // helper function can be used to merge objects in a way that respects any\n  // custom merge functions defined for their fields.\n  mergeObjects: MergeObjectsFunction;\n}\n\ntype MergeObjectsFunction = <T extends StoreObject | Reference>(\n  existing: T,\n  incoming: T\n) => T;\n\nexport type FieldReadFunction<\n  TExisting = any,\n  TReadResult = TExisting,\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = (\n  // When reading a field, one often needs to know about any existing\n  // value stored for that field. If the field is read before any value\n  // has been written to the cache, this existing parameter will be\n  // undefined, which makes it easy to use a default parameter expression\n  // to supply the initial value. This parameter is positional (rather\n  // than one of the named options) because that makes it possible for the\n  // developer to annotate it with a type, without also having to provide\n  // a whole new type for the options object.\n  existing: SafeReadonly<TExisting> | undefined,\n  options: TOptions\n) => TReadResult | undefined;\n\nexport type FieldMergeFunction<\n  TExisting = any,\n  TIncoming = TExisting,\n  // Passing the whole FieldFunctionOptions makes the current definition\n  // independent from its implementation\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions,\n> = (\n  existing: SafeReadonly<TExisting> | undefined,\n  // The incoming parameter needs to be positional as well, for the same\n  // reasons discussed in FieldReadFunction above.\n  incoming: SafeReadonly<TIncoming>,\n  options: TOptions\n) => SafeReadonly<TExisting>;\n\nconst nullKeyFieldsFn: KeyFieldsFunction = () => void 0;\nconst simpleKeyArgsFn: KeyArgsFunction = (_args, context) => context.fieldName;\n\n// These merge functions can be selected by specifying merge:true or\n// merge:false in a field policy.\nconst mergeTrueFn: FieldMergeFunction<any> = (\n  existing,\n  incoming,\n  { mergeObjects }\n) => mergeObjects(existing, incoming);\nconst mergeFalseFn: FieldMergeFunction<any> = (_, incoming) => incoming;\n\nexport type PossibleTypesMap = {\n  [supertype: string]: string[];\n};\n\ntype InternalFieldPolicy = {\n  typename: string;\n  keyFn?: KeyArgsFunction;\n  read?: FieldReadFunction<any>;\n  merge?: FieldMergeFunction<any>;\n};\n\nexport class Policies {\n  private typePolicies: {\n    [__typename: string]: {\n      keyFn?: KeyFieldsFunction;\n      merge?: FieldMergeFunction<any>;\n      fields: {\n        [fieldName: string]: InternalFieldPolicy;\n      };\n    };\n  } = {};\n\n  private toBeAdded: {\n    [__typename: string]: TypePolicy[];\n  } = {};\n\n  // Map from subtype names to sets of supertype names. Note that this\n  // representation inverts the structure of possibleTypes (whose keys are\n  // supertypes and whose values are arrays of subtypes) because it tends\n  // to be much more efficient to search upwards than downwards.\n  private supertypeMap = new Map<string, Set<string>>();\n\n  // Any fuzzy subtypes specified by possibleTypes will be converted to\n  // RegExp objects and recorded here. Every key of this map can also be\n  // found in supertypeMap. In many cases this Map will be empty, which\n  // means no fuzzy subtype checking will happen in fragmentMatches.\n  private fuzzySubtypes = new Map<string, RegExp>();\n\n  public readonly cache: InMemoryCache;\n\n  public readonly rootIdsByTypename: Record<string, string> = {};\n  public readonly rootTypenamesById: Record<string, string> = {};\n\n  public readonly usingPossibleTypes = false;\n\n  constructor(\n    private config: {\n      cache: InMemoryCache;\n      dataIdFromObject?: KeyFieldsFunction;\n      possibleTypes?: PossibleTypesMap;\n      typePolicies?: TypePolicies;\n    }\n  ) {\n    this.config = {\n      dataIdFromObject: defaultDataIdFromObject,\n      ...config,\n    };\n\n    this.cache = this.config.cache;\n\n    this.setRootTypename(\"Query\");\n    this.setRootTypename(\"Mutation\");\n    this.setRootTypename(\"Subscription\");\n\n    if (config.possibleTypes) {\n      this.addPossibleTypes(config.possibleTypes);\n    }\n\n    if (config.typePolicies) {\n      this.addTypePolicies(config.typePolicies);\n    }\n  }\n\n  public identify(\n    object: StoreObject,\n    partialContext?: Partial<KeyFieldsContext>\n  ): [string?, StoreObject?] {\n    const policies = this;\n\n    const typename =\n      (partialContext &&\n        (partialContext.typename || partialContext.storeObject?.__typename)) ||\n      object.__typename;\n\n    // It should be possible to write root Query fields with writeFragment,\n    // using { __typename: \"Query\", ... } as the data, but it does not make\n    // sense to allow the same identification behavior for the Mutation and\n    // Subscription types, since application code should never be writing\n    // directly to (or reading directly from) those root objects.\n    if (typename === this.rootTypenamesById.ROOT_QUERY) {\n      return [\"ROOT_QUERY\"];\n    }\n\n    // Default context.storeObject to object if not otherwise provided.\n    const storeObject =\n      (partialContext && partialContext.storeObject) || object;\n\n    const context: KeyFieldsContext = {\n      ...partialContext,\n      typename,\n      storeObject,\n      readField:\n        (partialContext && partialContext.readField) ||\n        (((...args) => {\n          const options = normalizeReadFieldOptions(args, storeObject);\n          return policies.readField(options, {\n            store: policies.cache[\"data\"],\n            variables: options.variables,\n          });\n        }) satisfies ReadFieldFunction),\n    };\n\n    let id: KeyFieldsResult;\n\n    const policy = typename && this.getTypePolicy(typename);\n    let keyFn = (policy && policy.keyFn) || this.config.dataIdFromObject;\n\n    disableWarningsSlot.withValue(true, () => {\n      while (keyFn) {\n        const specifierOrId = keyFn({ ...object, ...storeObject }, context);\n        if (isArray(specifierOrId)) {\n          keyFn = keyFieldsFnFromSpecifier(specifierOrId);\n        } else {\n          id = specifierOrId;\n          break;\n        }\n      }\n    });\n\n    id = id ? String(id) : void 0;\n    return context.keyObject ? [id, context.keyObject] : [id];\n  }\n\n  public addTypePolicies(typePolicies: TypePolicies) {\n    Object.keys(typePolicies).forEach((typename) => {\n      const { queryType, mutationType, subscriptionType, ...incoming } =\n        typePolicies[typename];\n\n      // Though {query,mutation,subscription}Type configurations are rare,\n      // it's important to call setRootTypename as early as possible,\n      // since these configurations should apply consistently for the\n      // entire lifetime of the cache. Also, since only one __typename can\n      // qualify as one of these root types, these three properties cannot\n      // be inherited, unlike the rest of the incoming properties. That\n      // restriction is convenient, because the purpose of this.toBeAdded\n      // is to delay the processing of type/field policies until the first\n      // time they're used, allowing policies to be added in any order as\n      // long as all relevant policies (including policies for supertypes)\n      // have been added by the time a given policy is used for the first\n      // time. In other words, since inheritance doesn't matter for these\n      // properties, there's also no need to delay their processing using\n      // the this.toBeAdded queue.\n      if (queryType) this.setRootTypename(\"Query\", typename);\n      if (mutationType) this.setRootTypename(\"Mutation\", typename);\n      if (subscriptionType) this.setRootTypename(\"Subscription\", typename);\n\n      if (hasOwn.call(this.toBeAdded, typename)) {\n        this.toBeAdded[typename].push(incoming);\n      } else {\n        this.toBeAdded[typename] = [incoming];\n      }\n    });\n  }\n\n  private updateTypePolicy(\n    typename: string,\n    incoming: TypePolicy,\n    existingFieldPolicies: Record<string, InternalFieldPolicy>\n  ) {\n    const existing = this.getTypePolicy(typename);\n    const { keyFields, fields } = incoming;\n\n    function setMerge(\n      existing: { merge?: FieldMergeFunction | boolean },\n      merge?: FieldMergeFunction | boolean\n    ) {\n      existing.merge =\n        typeof merge === \"function\" ? merge\n          // Pass merge:true as a shorthand for a merge implementation\n          // that returns options.mergeObjects(existing, incoming).\n        : merge === true ? mergeTrueFn\n          // Pass merge:false to make incoming always replace existing\n          // without any warnings about data clobbering.\n        : merge === false ? mergeFalseFn\n        : existing.merge;\n    }\n\n    // Type policies can define merge functions, as an alternative to\n    // using field policies to merge child objects.\n    setMerge(existing, incoming.merge);\n\n    existing.keyFn =\n      // Pass false to disable normalization for this typename.\n      keyFields === false ? nullKeyFieldsFn\n        // Pass an array of strings to use those fields to compute a\n        // composite ID for objects of this typename.\n      : isArray(keyFields) ? keyFieldsFnFromSpecifier(keyFields)\n        // Pass a function to take full control over identification.\n      : typeof keyFields === \"function\" ? keyFields\n        // Leave existing.keyFn unchanged if above cases fail.\n      : existing.keyFn;\n\n    if (fields) {\n      Object.keys(fields).forEach((fieldName) => {\n        let existing = existingFieldPolicies[fieldName] as\n          | InternalFieldPolicy\n          | undefined;\n        // Field policy inheritance is atomic/shallow: you can't inherit a\n        // field policy and then override just its read function, since read\n        // and merge functions often need to cooperate, so changing only one\n        // of them would be a recipe for inconsistency.\n        // So here we avoid merging an inherited field policy with an updated one.\n        if (!existing || existing?.typename !== typename) {\n          existing = existingFieldPolicies[fieldName] = { typename };\n        }\n        const incoming = fields[fieldName];\n\n        if (typeof incoming === \"function\") {\n          existing.read = incoming;\n        } else {\n          const { keyArgs, read, merge } = incoming;\n\n          existing.keyFn =\n            // Pass false to disable argument-based differentiation of\n            // field identities.\n            keyArgs === false ? simpleKeyArgsFn\n              // Pass an array of strings to use named arguments to\n              // compute a composite identity for the field.\n            : isArray(keyArgs) ? keyArgsFnFromSpecifier(keyArgs)\n              // Pass a function to take full control over field identity.\n            : typeof keyArgs === \"function\" ? keyArgs\n              // Leave existing.keyFn unchanged if above cases fail.\n            : existing.keyFn;\n\n          if (typeof read === \"function\") {\n            existing.read = read;\n          }\n\n          setMerge(existing, merge);\n        }\n\n        if (existing.read && existing.merge) {\n          // If we have both a read and a merge function, assume\n          // keyArgs:false, because read and merge together can take\n          // responsibility for interpreting arguments in and out. This\n          // default assumption can always be overridden by specifying\n          // keyArgs explicitly in the FieldPolicy.\n          existing.keyFn = existing.keyFn || simpleKeyArgsFn;\n        }\n      });\n    }\n  }\n\n  private setRootTypename(\n    which: \"Query\" | \"Mutation\" | \"Subscription\",\n    typename: string = which\n  ) {\n    const rootId = \"ROOT_\" + which.toUpperCase();\n    const old = this.rootTypenamesById[rootId];\n    if (typename !== old) {\n      invariant(\n        !old || old === which,\n        `Cannot change root %s __typename more than once`,\n        which\n      );\n      // First, delete any old __typename associated with this rootId from\n      // rootIdsByTypename.\n      if (old) delete this.rootIdsByTypename[old];\n      // Now make this the only __typename that maps to this rootId.\n      this.rootIdsByTypename[typename] = rootId;\n      // Finally, update the __typename associated with this rootId.\n      this.rootTypenamesById[rootId] = typename;\n    }\n  }\n\n  public addPossibleTypes(possibleTypes: PossibleTypesMap) {\n    (this.usingPossibleTypes as boolean) = true;\n    Object.keys(possibleTypes).forEach((supertype) => {\n      // Make sure all types have an entry in this.supertypeMap, even if\n      // their supertype set is empty, so we can return false immediately\n      // from policies.fragmentMatches for unknown supertypes.\n      this.getSupertypeSet(supertype, true);\n\n      possibleTypes[supertype].forEach((subtype) => {\n        this.getSupertypeSet(subtype, true)!.add(supertype);\n        const match = subtype.match(TypeOrFieldNameRegExp);\n        if (!match || match[0] !== subtype) {\n          // TODO Don't interpret just any invalid typename as a RegExp.\n          this.fuzzySubtypes.set(subtype, new RegExp(subtype));\n        }\n      });\n    });\n  }\n\n  private getTypePolicy(typename: string): Policies[\"typePolicies\"][string] {\n    if (!hasOwn.call(this.typePolicies, typename)) {\n      const policy: Policies[\"typePolicies\"][string] = (this.typePolicies[\n        typename\n      ] = {} as any);\n      policy.fields = {};\n\n      // When the TypePolicy for typename is first accessed, instead of\n      // starting with an empty policy object, inherit any properties or\n      // fields from the type policies of the supertypes of typename.\n      //\n      // Any properties or fields defined explicitly within the TypePolicy\n      // for typename will take precedence, and if there are multiple\n      // supertypes, the properties of policies whose types were added\n      // later via addPossibleTypes will take precedence over those of\n      // earlier supertypes. TODO Perhaps we should warn about these\n      // conflicts in development, and recommend defining the property\n      // explicitly in the subtype policy?\n      //\n      // Field policy inheritance is atomic/shallow: you can't inherit a\n      // field policy and then override just its read function, since read\n      // and merge functions often need to cooperate, so changing only one\n      // of them would be a recipe for inconsistency.\n      //\n      // Once the TypePolicy for typename has been accessed, its properties can\n      // still be updated directly using addTypePolicies, but future changes to\n      // inherited supertype policies will not be reflected in this subtype\n      // policy, because this code runs at most once per typename.\n      let supertypes = this.supertypeMap.get(typename);\n      if (!supertypes && this.fuzzySubtypes.size) {\n        // To make the inheritance logic work for unknown typename strings that\n        // may have fuzzy supertypes, we give this typename an empty supertype\n        // set and then populate it with any fuzzy supertypes that match.\n        supertypes = this.getSupertypeSet(typename, true)!;\n        // This only works for typenames that are directly matched by a fuzzy\n        // supertype. What if there is an intermediate chain of supertypes?\n        // While possible, that situation can only be solved effectively by\n        // specifying the intermediate relationships via possibleTypes, manually\n        // and in a non-fuzzy way.\n        this.fuzzySubtypes.forEach((regExp, fuzzy) => {\n          if (regExp.test(typename)) {\n            // The fuzzy parameter is just the original string version of regExp\n            // (not a valid __typename string), but we can look up the\n            // associated supertype(s) in this.supertypeMap.\n            const fuzzySupertypes = this.supertypeMap.get(fuzzy);\n            if (fuzzySupertypes) {\n              fuzzySupertypes.forEach((supertype) =>\n                supertypes!.add(supertype)\n              );\n            }\n          }\n        });\n      }\n      if (supertypes && supertypes.size) {\n        supertypes.forEach((supertype) => {\n          const { fields, ...rest } = this.getTypePolicy(supertype);\n          Object.assign(policy, rest);\n          Object.assign(policy.fields, fields);\n        });\n      }\n    }\n\n    const inbox = this.toBeAdded[typename];\n    if (inbox && inbox.length) {\n      // Merge the pending policies into this.typePolicies, in the order they\n      // were originally passed to addTypePolicy.\n      inbox.splice(0).forEach((policy) => {\n        this.updateTypePolicy(\n          typename,\n          policy,\n          this.typePolicies[typename].fields\n        );\n      });\n    }\n\n    return this.typePolicies[typename];\n  }\n\n  private getFieldPolicy(\n    typename: string | undefined,\n    fieldName: string\n  ): InternalFieldPolicy | undefined {\n    if (typename) {\n      return this.getTypePolicy(typename).fields[fieldName];\n    }\n  }\n\n  private getSupertypeSet(\n    subtype: string,\n    createIfMissing: boolean\n  ): Set<string> | undefined {\n    let supertypeSet = this.supertypeMap.get(subtype);\n    if (!supertypeSet && createIfMissing) {\n      this.supertypeMap.set(subtype, (supertypeSet = new Set<string>()));\n    }\n    return supertypeSet;\n  }\n\n  public fragmentMatches(\n    fragment: InlineFragmentNode | FragmentDefinitionNode,\n    typename: string | undefined,\n    result?: Record<string, any>,\n    variables?: Record<string, any>\n  ): boolean {\n    if (!fragment.typeCondition) return true;\n\n    // If the fragment has a type condition but the object we're matching\n    // against does not have a __typename, the fragment cannot match.\n    if (!typename) return false;\n\n    const supertype = fragment.typeCondition.name.value;\n    // Common case: fragment type condition and __typename are the same.\n    if (typename === supertype) return true;\n\n    if (this.usingPossibleTypes && this.supertypeMap.has(supertype)) {\n      const typenameSupertypeSet = this.getSupertypeSet(typename, true)!;\n      const workQueue = [typenameSupertypeSet];\n      const maybeEnqueue = (subtype: string) => {\n        const supertypeSet = this.getSupertypeSet(subtype, false);\n        if (\n          supertypeSet &&\n          supertypeSet.size &&\n          workQueue.indexOf(supertypeSet) < 0\n        ) {\n          workQueue.push(supertypeSet);\n        }\n      };\n\n      // We need to check fuzzy subtypes only if we encountered fuzzy\n      // subtype strings in addPossibleTypes, and only while writing to\n      // the cache, since that's when selectionSetMatchesResult gives a\n      // strong signal of fragment matching. The StoreReader class calls\n      // policies.fragmentMatches without passing a result object, so\n      // needToCheckFuzzySubtypes is always false while reading.\n      let needToCheckFuzzySubtypes = !!(result && this.fuzzySubtypes.size);\n      let checkingFuzzySubtypes = false;\n\n      // It's important to keep evaluating workQueue.length each time through\n      // the loop, because the queue can grow while we're iterating over it.\n      for (let i = 0; i < workQueue.length; ++i) {\n        const supertypeSet = workQueue[i];\n\n        if (supertypeSet.has(supertype)) {\n          if (!typenameSupertypeSet.has(supertype)) {\n            if (checkingFuzzySubtypes) {\n              invariant.warn(\n                `Inferring subtype %s of supertype %s`,\n                typename,\n                supertype\n              );\n            }\n            // Record positive results for faster future lookup.\n            // Unfortunately, we cannot safely cache negative results,\n            // because new possibleTypes data could always be added to the\n            // Policies class.\n            typenameSupertypeSet.add(supertype);\n          }\n          return true;\n        }\n\n        supertypeSet.forEach(maybeEnqueue);\n\n        if (\n          needToCheckFuzzySubtypes &&\n          // Start checking fuzzy subtypes only after exhausting all\n          // non-fuzzy subtypes (after the final iteration of the loop).\n          i === workQueue.length - 1 &&\n          // We could wait to compare fragment.selectionSet to result\n          // after we verify the supertype, but this check is often less\n          // expensive than that search, and we will have to do the\n          // comparison anyway whenever we find a potential match.\n          selectionSetMatchesResult(fragment.selectionSet, result!, variables)\n        ) {\n          // We don't always need to check fuzzy subtypes (if no result\n          // was provided, or !this.fuzzySubtypes.size), but, when we do,\n          // we only want to check them once.\n          needToCheckFuzzySubtypes = false;\n          checkingFuzzySubtypes = true;\n\n          // If we find any fuzzy subtypes that match typename, extend the\n          // workQueue to search through the supertypes of those fuzzy\n          // subtypes. Otherwise the for-loop will terminate and we'll\n          // return false below.\n          this.fuzzySubtypes.forEach((regExp, fuzzyString) => {\n            const match = typename.match(regExp);\n            if (match && match[0] === typename) {\n              maybeEnqueue(fuzzyString);\n            }\n          });\n        }\n      }\n    }\n\n    return false;\n  }\n\n  public hasKeyArgs(typename: string | undefined, fieldName: string) {\n    const policy = this.getFieldPolicy(typename, fieldName);\n    return !!(policy && policy.keyFn);\n  }\n\n  public getStoreFieldName(fieldSpec: FieldSpecifier): string {\n    const { typename, fieldName } = fieldSpec;\n    const policy = this.getFieldPolicy(typename, fieldName);\n    let storeFieldName: Exclude<ReturnType<KeyArgsFunction>, KeySpecifier>;\n\n    let keyFn = policy && policy.keyFn;\n    if (keyFn && typename) {\n      const context: Parameters<KeyArgsFunction>[1] = {\n        typename,\n        fieldName,\n        field: fieldSpec.field || null,\n        variables: fieldSpec.variables,\n      };\n      const args = argsFromFieldSpecifier(fieldSpec);\n      while (keyFn) {\n        const specifierOrString = keyFn(args, context);\n        if (isArray(specifierOrString)) {\n          keyFn = keyArgsFnFromSpecifier(specifierOrString);\n        } else {\n          // If the custom keyFn returns a falsy value, fall back to\n          // fieldName instead.\n          storeFieldName = specifierOrString || fieldName;\n          break;\n        }\n      }\n    }\n\n    if (storeFieldName === void 0) {\n      storeFieldName =\n        fieldSpec.field ?\n          storeKeyNameFromField(fieldSpec.field, fieldSpec.variables)\n        : getStoreKeyName(fieldName, argsFromFieldSpecifier(fieldSpec));\n    }\n\n    // Returning false from a keyArgs function is like configuring\n    // keyArgs: false, but more dynamic.\n    if (storeFieldName === false) {\n      return fieldName;\n    }\n\n    // Make sure custom field names start with the actual field.name.value\n    // of the field, so we can always figure out which properties of a\n    // StoreObject correspond to which original field names.\n    return fieldName === fieldNameFromStoreName(storeFieldName) ? storeFieldName\n      : fieldName + \":\" + storeFieldName;\n  }\n\n  public readField<V = StoreValue>(\n    options: ReadFieldOptions,\n    context: ReadMergeModifyContext\n  ): SafeReadonly<V> | undefined {\n    const objectOrReference = options.from;\n    if (!objectOrReference) return;\n\n    const nameOrField = options.field || options.fieldName;\n    if (!nameOrField) return;\n\n    if (options.typename === void 0) {\n      const typename = context.store.getFieldValue<string>(\n        objectOrReference,\n        \"__typename\"\n      );\n      if (typename) options.typename = typename;\n    }\n\n    const storeFieldName = this.getStoreFieldName(options);\n    const fieldName = fieldNameFromStoreName(storeFieldName);\n    const existing = context.store.getFieldValue<V>(\n      objectOrReference,\n      storeFieldName\n    );\n    const policy = this.getFieldPolicy(options.typename, fieldName);\n    const read = policy && policy.read;\n\n    if (read) {\n      const readOptions = makeFieldFunctionOptions(\n        this,\n        objectOrReference,\n        options,\n        context,\n        context.store.getStorage(\n          isReference(objectOrReference) ?\n            objectOrReference.__ref\n          : objectOrReference,\n          storeFieldName\n        )\n      );\n\n      // Call read(existing, readOptions) with cacheSlot holding this.cache.\n      return cacheSlot.withValue(this.cache, read, [\n        existing,\n        readOptions,\n      ]) as SafeReadonly<V>;\n    }\n\n    return existing;\n  }\n\n  public getReadFunction(\n    typename: string | undefined,\n    fieldName: string\n  ): FieldReadFunction | undefined {\n    const policy = this.getFieldPolicy(typename, fieldName);\n    return policy && policy.read;\n  }\n\n  public getMergeFunction(\n    parentTypename: string | undefined,\n    fieldName: string,\n    childTypename: string | undefined\n  ): FieldMergeFunction | undefined {\n    let policy:\n      | Policies[\"typePolicies\"][string]\n      | Policies[\"typePolicies\"][string][\"fields\"][string]\n      | undefined = this.getFieldPolicy(parentTypename, fieldName);\n    let merge = policy && policy.merge;\n    if (!merge && childTypename) {\n      policy = this.getTypePolicy(childTypename);\n      merge = policy && policy.merge;\n    }\n    return merge;\n  }\n\n  public runMergeFunction(\n    existing: StoreValue,\n    incoming: StoreValue,\n    { field, typename, merge }: MergeInfo,\n    context: WriteContext,\n    storage?: StorageType\n  ) {\n    if (merge === mergeTrueFn) {\n      // Instead of going to the trouble of creating a full\n      // FieldFunctionOptions object and calling mergeTrueFn, we can\n      // simply call mergeObjects, as mergeTrueFn would.\n      return makeMergeObjectsFunction(context.store)(\n        existing as StoreObject,\n        incoming as StoreObject\n      );\n    }\n\n    if (merge === mergeFalseFn) {\n      // Likewise for mergeFalseFn, whose implementation is even simpler.\n      return incoming;\n    }\n\n    // If cache.writeQuery or cache.writeFragment was called with\n    // options.overwrite set to true, we still call merge functions, but\n    // the existing data is always undefined, so the merge function will\n    // not attempt to combine the incoming data with the existing data.\n    if (context.overwrite) {\n      existing = void 0;\n    }\n\n    return merge(\n      existing,\n      incoming,\n      makeFieldFunctionOptions(\n        this,\n        // Unlike options.readField for read functions, we do not fall\n        // back to the current object if no foreignObjOrRef is provided,\n        // because it's not clear what the current object should be for\n        // merge functions: the (possibly undefined) existing object, or\n        // the incoming object? If you think your merge function needs\n        // to read sibling fields in order to produce a new value for\n        // the current field, you might want to rethink your strategy,\n        // because that's a recipe for making merge behavior sensitive\n        // to the order in which fields are written into the cache.\n        // However, readField(name, ref) is useful for merge functions\n        // that need to deduplicate child objects and references.\n        void 0,\n        {\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        },\n        context,\n        storage || {}\n      )\n    );\n  }\n}\n\nfunction makeFieldFunctionOptions(\n  policies: Policies,\n  objectOrReference: StoreObject | Reference | undefined,\n  fieldSpec: FieldSpecifier,\n  context: ReadMergeModifyContext,\n  storage: StorageType\n): FieldFunctionOptions {\n  const storeFieldName = policies.getStoreFieldName(fieldSpec);\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const variables = fieldSpec.variables || context.variables;\n  const { toReference, canRead } = context.store;\n\n  return {\n    args: argsFromFieldSpecifier(fieldSpec),\n    field: fieldSpec.field || null,\n    fieldName,\n    storeFieldName,\n    variables,\n    isReference,\n    toReference,\n    storage,\n    cache: policies.cache,\n    canRead,\n    readField<T>(...args: any[]) {\n      return policies.readField<T>(\n        normalizeReadFieldOptions(args, objectOrReference, variables),\n        context\n      );\n    },\n    mergeObjects: makeMergeObjectsFunction(context.store),\n  };\n}\n\nexport function normalizeReadFieldOptions(\n  readFieldArgs: any[],\n  objectOrReference: StoreObject | Reference | undefined,\n  variables?: ReadMergeModifyContext[\"variables\"]\n): ReadFieldOptions {\n  const { 0: fieldNameOrOptions, 1: from, length: argc } = readFieldArgs;\n\n  let options: ReadFieldOptions;\n\n  if (typeof fieldNameOrOptions === \"string\") {\n    options = {\n      fieldName: fieldNameOrOptions,\n      // Default to objectOrReference only when no second argument was\n      // passed for the from parameter, not when undefined is explicitly\n      // passed as the second argument.\n      from: argc > 1 ? from : objectOrReference,\n    };\n  } else {\n    options = { ...fieldNameOrOptions };\n    // Default to objectOrReference only when fieldNameOrOptions.from is\n    // actually omitted, rather than just undefined.\n    if (!hasOwn.call(options, \"from\")) {\n      options.from = objectOrReference;\n    }\n  }\n\n  if (__DEV__ && options.from === void 0) {\n    invariant.warn(\n      `Undefined 'from' passed to readField with arguments %s`,\n      stringifyForDisplay(Array.from(readFieldArgs))\n    );\n  }\n\n  if (void 0 === options.variables) {\n    options.variables = variables;\n  }\n\n  return options;\n}\n\nfunction makeMergeObjectsFunction(\n  store: NormalizedCache\n): MergeObjectsFunction {\n  return function mergeObjects(existing, incoming) {\n    if (isArray(existing) || isArray(incoming)) {\n      throw newInvariantError(\"Cannot automatically merge arrays\");\n    }\n\n    // These dynamic checks are necessary because the parameters of a\n    // custom merge function can easily have the any type, so the type\n    // system cannot always enforce the StoreObject | Reference parameter\n    // types of options.mergeObjects.\n    if (isNonNullObject(existing) && isNonNullObject(incoming)) {\n      const eType = store.getFieldValue(existing, \"__typename\");\n      const iType = store.getFieldValue(incoming, \"__typename\");\n      const typesDiffer = eType && iType && eType !== iType;\n\n      if (typesDiffer) {\n        return incoming;\n      }\n\n      if (isReference(existing) && storeValueIsStoreObject(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // existing.__ref, preferring/overwriting any fields contributed by the\n        // newer incoming StoreObject.\n        store.merge(existing.__ref, incoming);\n        return existing;\n      }\n\n      if (storeValueIsStoreObject(existing) && isReference(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // incoming.__ref, taking fields from the older existing object only if\n        // those fields are not already present in the newer StoreObject\n        // identified by incoming.__ref.\n        store.merge(existing, incoming.__ref);\n        return incoming;\n      }\n\n      if (\n        storeValueIsStoreObject(existing) &&\n        storeValueIsStoreObject(incoming)\n      ) {\n        return { ...existing, ...incoming };\n      }\n    }\n\n    return incoming;\n  };\n}\n"],"mappings":"AAQA,SAASA,mBAAT,QAAoC,wBAAwB;AAM5D,SAASC,WAAT,QAA4B,0BAA0B;AACtD,SAASC,OAAT,QAAwB,sCAAsC;AAE9D,SACEC,wBAAwB,EACxBC,eAAe,EACfC,OAAO,EACPC,eAAe,EACfC,qBAAqB,EACrBC,mBAAmB,QACd,mCAAmC;AAC1C,SACEC,SAAS,EACTC,iBAAiB,QACZ,oCAAoC;AAW3C,SACEC,uBAAuB,EACvBC,sBAAsB,EACtBC,MAAM,EACNC,yBAAyB,EACzBC,uBAAuB,EACvBC,qBAAqB,QAChB,cAAc;AAErB,SACEC,sBAAsB,EACtBC,wBAAwB,QACnB,oBAAoB;AAC3B,SAASC,SAAT,QAA0B,mBAAmB;AAyH7C,SAASC,sBAAsBA,CAACC,IAAoB,EAApD;EACE,OACEA,IAAI,CAACC,IADT,KACkB,KAAK,IAAID,IAAI,CAACC,IADhC,GAEMD,IAAI,CAACE,KAAX,GAAmBpB,wBAAwB,CAACkB,IAAI,CAACE,KAAK,EAAEF,IAAI,CAACG,SAAS,IAChE,IAAI;AAEV;AA6FA,MAAMC,eAAN,GAA2CA,CAAA,KAAM,KAAK,CAAC;AACvD,MAAMC,eAAN,GAAyCA,CAACC,KAAK,EAAEC,OAAO,KAAKA,OAAO,CAACC,SAAS;AAE9E;AACA;AACA,MAAMC,WAAN,GAA6CA,CAC3CC,QAAQ,EACRC,QAAQ,EACR;EAAEC;AAHJ,CAGkB,KACbA,YAAY,CAACF,QAAQ,EAAEC,QAAQ,CAAC;AACrC,MAAME,YAAN,GAA8CA,CAACC,CAAC,EAAEH,QAAQ,KAAKA,QAAQ;AAavE,aAAaI,QAAb;EAmCYC,MAAZ;EAlCUC,YAAV,GAQM,CARN,CAQQ;EAEEC,SAAV,GAEM,CAFN,CAEQ;EAEN;EACA;EACA;EACA;EACQC,YAAV,GAAyB,IAAIC,GAAG,CAAhC,CAAuD;EAErD;EACA;EACA;EACA;EACQC,aAAV,GAA0B,IAAID,GAAG,CAAjC,CAAmD;EAEjCE,KAAK;EAELC,iBAAlB,GAA8D,CAA9D,CAAgE;EAC9CC,iBAAlB,GAA8D,CAA9D,CAAgE;EAE9CC,kBAAlB,GAAuC,KAAK;EAE1CC,WAAFA,CACYV,MAKP,EANL;IACY,IAAZ,CAAAA,MAAA,GAAYA,MAAM;IAOd,IAAI,CAACA,MAAT,GAAkB;MACZW,gBAAgB,EAAErC,uBAAuB;MACzC,GAAG0B;IACT,CAAK;IAED,IAAI,CAACM,KAAT,GAAiB,IAAI,CAACN,MAAM,CAACM,KAAK;IAE9B,IAAI,CAACM,eAAe,CAAC,OAAO,CAAC;IAC7B,IAAI,CAACA,eAAe,CAAC,UAAU,CAAC;IAChC,IAAI,CAACA,eAAe,CAAC,cAAc,CAAC;IAEpC,IAAIZ,MAAM,CAACa,aAAa,EAAE;MACxB,IAAI,CAACC,gBAAgB,CAACd,MAAM,CAACa,aAAa,CAAC;IAC7C;IAEA,IAAIb,MAAM,CAACC,YAAY,EAAE;MACvB,IAAI,CAACc,eAAe,CAACf,MAAM,CAACC,YAAY,CAAC;IAC3C;EACF;EAEOe,QAAQA,CACbC,MAAmB,EACnBC,cAA0C,EAF9C;IAII,MAAMC,QAAV,GAAqB,IAAI;IAErB,MAAMC,QAAV,GACOF,cADP,KAESA,cAAc,CAACE,QAAxB,IAAoCF,cAAc,CAACG,WAAW,EAAEC,UAAU,CAAC,IACrEL,MAAM,CAACK,UAAU;IAEnB;IACA;IACA;IACA;IACA;IACA,IAAIF,QAAR,KAAqB,IAAI,CAACZ,iBAAiB,CAACe,UAAU,EAAE;MAClD,OAAO,CAAC,YAAY,CAAC;IACvB;IAEA;IACA,MAAMF,WAAV,GACOH,cADP,IACyBA,cAAc,CAACG,WAAW,IAAKJ,MAAM;IAE1D,MAAM1B,OAAV,GAAsC;MAChC,GAAG2B,cAAc;MACjBE,QAAQ;MACRC,WAAW;MACXG,SAAS,EACNN,cADT,IAC2BA,cAAc,CAACM,SAAS,KACzC,CAAC,GAAGvC,IAAI,KAAlB;QACU,MAAMwC,OAAhB,GAA0BC,yBAAyB,CAACzC,IAAI,EAAEoC,WAAW,CAAC;QAC5D,OAAOF,QAAQ,CAACK,SAAS,CAACC,OAAO,EAAE;UACjCE,KAAK,EAAER,QAAQ,CAACb,KAAK,CAAC,MAAM,CAAC;UAC7BnB,SAAS,EAAEsC,OAAO,CAACtC;QAC/B,CAAW,CAAC;MACJ,CAAC;IACT,CAAK;IAED,IAAIyC,EAAmB;IAEvB,MAAMC,MAAV,GAAmBT,QAAnB,IAA+B,IAAI,CAACU,aAAa,CAACV,QAAQ,CAAC;IACvD,IAAIW,KAAR,GAAiBF,MAAjB,IAA2BA,MAAM,CAACE,KAAK,IAAK,IAAI,CAAC/B,MAAM,CAACW,gBAAgB;IAEpEhD,mBAAmB,CAACqE,SAAS,CAAC,IAAI,EAAE,MAAxC;MACM,OAAOD,KAAK,EAAE;QACZ,MAAME,aAAd,GAA8BF,KAAK,CAAC;UAAE,GAAGd,MAAM;UAAE,GAAGI;QAApD,CAAiE,EAAE9B,OAAO,CAAC;QACnE,IAAIvB,OAAO,CAACiE,aAAa,CAAC,EAAE;UAC1BF,KAAV,GAAkBlD,wBAAwB,CAACoD,aAAa,CAAC;QACjD,OAAO;UACLL,EAAV,GAAeK,aAAa;UAClB;QACF;MACF;IACF,CAAC,CAAC;IAEFL,EAAJ,GAASA,EAAT,GAAcM,MAAM,CAACN,EAAE,IAAI,KAAK,CAAC;IAC7B,OAAOrC,OAAO,CAAC4C,SAAnB,GAA+B,CAACP,EAAE,EAAErC,OAAO,CAAC4C,SAAS,IAAI,CAACP,EAAE,CAAC;EAC3D;EAEOb,eAAeA,CAACd,YAA0B,EAAnD;IACImC,MAAM,CAACC,IAAI,CAACpC,YAAY,CAAC,CAACqC,OAAO,CAAElB,QAAQ,IAA/C;MACM,MAAM;QAAEmB,SAAS;QAAEC,YAAY;QAAEC,gBAAgB;QAAE,GAAG9C;MAA5D,IACQM,YAAY,CAACmB,QAAQ,CAAC;MAExB;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA,IAAImB,SAAS,EAAE,IAAI,CAAC3B,eAAe,CAAC,OAAO,EAAEQ,QAAQ,CAAC;MACtD,IAAIoB,YAAY,EAAE,IAAI,CAAC5B,eAAe,CAAC,UAAU,EAAEQ,QAAQ,CAAC;MAC5D,IAAIqB,gBAAgB,EAAE,IAAI,CAAC7B,eAAe,CAAC,cAAc,EAAEQ,QAAQ,CAAC;MAEpE,IAAI5C,MAAM,CAACkE,IAAI,CAAC,IAAI,CAACxC,SAAS,EAAEkB,QAAQ,CAAC,EAAE;QACzC,IAAI,CAAClB,SAAS,CAACkB,QAAQ,CAAC,CAACuB,IAAI,CAAChD,QAAQ,CAAC;MACzC,OAAO;QACL,IAAI,CAACO,SAAS,CAACkB,QAAQ,IAAI,CAACzB,QAAQ,CAAC;MACvC;IACF,CAAC,CAAC;EACJ;EAEQiD,gBAAgBA,CACtBxB,QAAgB,EAChBzB,QAAoB,EACpBkD,qBAA0D,EAH9D;IAKI,MAAMnD,QAAV,GAAqB,IAAI,CAACoC,aAAa,CAACV,QAAQ,CAAC;IAC7C,MAAM;MAAE0B,SAAS;MAAEC;IAAvB,IAAkCpD,QAAQ;IAEtC,SAASqD,QAAQA,CACftD,QAAkD,EAClDuD,KAAoC,EAF1C;MAIMvD,QAAQ,CAACuD,KAAf,GACQ,OAAOA,KAAf,KAAyB,UAAzB,GAAsCA;MAC5B;MACA;MAAA,EACAA,KAAV,KAAoB,IAApB,GAA2BxD;MACjB;MACA;MAAA,EACAwD,KAAV,KAAoB,KAApB,GAA4BpD,YAA5B,GACUH,QAAQ,CAACuD,KAAK;IACpB;IAEA;IACA;IACAD,QAAQ,CAACtD,QAAQ,EAAEC,QAAQ,CAACsD,KAAK,CAAC;IAElCvD,QAAQ,CAACqC,KAAb;IACM;IACAe,SAAN,KAAoB,KAApB,GAA4B1D;IACpB;IACA;IAAA,EACApB,OAAO,CAAC8E,SAAS,IAAIjE,wBAAwB,CAACiE,SAAS;IACvD;IAAA,EACA,OAAOA,SAAf,KAA6B,UAA7B,GAA0CA;IAClC;IAAA,EACApD,QAAQ,CAACqC,KAAK;IAElB,IAAIgB,MAAM,EAAE;MACVX,MAAM,CAACC,IAAI,CAACU,MAAM,CAAC,CAACT,OAAO,CAAE9C,SAAS,IAA5C;QACQ,IAAIE,QAAZ,GAAuBmD,qBAAqB,CAACrD,SAAS,CAEjC;QACb;QACA;QACA;QACA;QACA;QACA,IAAI,CAACE,QAAb,IAAyBA,QAAQ,EAAE0B,QAAnC,KAAgDA,QAAQ,EAAE;UAChD1B,QAAV,GAAqBmD,qBAAqB,CAACrD,SAAS,IAAI;YAAE4B;UAA1D,CAAoE;QAC5D;QACA,MAAMzB,QAAd,GAAyBoD,MAAM,CAACvD,SAAS,CAAC;QAElC,IAAI,OAAOG,QAAnB,KAAgC,UAAU,EAAE;UAClCD,QAAQ,CAACwD,IAAnB,GAA0BvD,QAAQ;QAC1B,OAAO;UACL,MAAM;YAAEwD,OAAO;YAAED,IAAI;YAAED;UAAjC,IAA2CtD,QAAQ;UAEzCD,QAAQ,CAACqC,KAAnB;UACY;UACA;UACAoB,OAAZ,KAAwB,KAAxB,GAAgC9D;UAClB;UACA;UAAA,EACArB,OAAO,CAACmF,OAAO,IAAIvE,sBAAsB,CAACuE,OAAO;UACjD;UAAA,EACA,OAAOA,OAArB,KAAiC,UAAjC,GAA8CA;UAChC;UAAA,EACAzD,QAAQ,CAACqC,KAAK;UAElB,IAAI,OAAOmB,IAArB,KAA8B,UAAU,EAAE;YAC9BxD,QAAQ,CAACwD,IAArB,GAA4BA,IAAI;UACtB;UAEAF,QAAQ,CAACtD,QAAQ,EAAEuD,KAAK,CAAC;QAC3B;QAEA,IAAIvD,QAAQ,CAACwD,IAArB,IAA6BxD,QAAQ,CAACuD,KAAK,EAAE;UACnC;UACA;UACA;UACA;UACA;UACAvD,QAAQ,CAACqC,KAAnB,GAA2BrC,QAAQ,CAACqC,KAApC,IAA6C1C,eAAe;QACpD;MACF,CAAC,CAAC;IACJ;EACF;EAEQuB,eAAeA,CACrBwC,KAA4C,EAC5ChC,QAFJ,GAEuBgC,KAAK,EAF5B;IAII,MAAMC,MAAV,GAAmB,OAAnB,GAA6BD,KAAK,CAACE,WAAW,CAA9C,CAAgD;IAC5C,MAAMC,GAAV,GAAgB,IAAI,CAAC/C,iBAAiB,CAAC6C,MAAM,CAAC;IAC1C,IAAIjC,QAAR,KAAqBmC,GAAG,EAAE;MACpBnF,SAAN,CACQ,CAACmF,GADT,IACgBA,GADhB,KACwBH,KADxB,MAGQA,KAHR,CAIO;MACD;MACA;MACA,IAAIG,GAAG,EAAE,OAAO,IAAI,CAAChD,iBAAiB,CAACgD,GAAG,CAAC;MAC3C;MACA,IAAI,CAAChD,iBAAiB,CAACa,QAAQ,IAAIiC,MAAM;MACzC;MACA,IAAI,CAAC7C,iBAAiB,CAAC6C,MAAM,IAAIjC,QAAQ;IAC3C;EACF;EAEON,gBAAgBA,CAACD,aAA+B,EAAzD;IACK,IAAI,CAACJ,kBAAV,GAA2C,IAAI;IAC3C2B,MAAM,CAACC,IAAI,CAACxB,aAAa,CAAC,CAACyB,OAAO,CAAEkB,SAAS,IAAjD;MACM;MACA;MACA;MACA,IAAI,CAACC,eAAe,CAACD,SAAS,EAAE,IAAI,CAAC;MAErC3C,aAAa,CAAC2C,SAAS,CAAC,CAAClB,OAAO,CAAEoB,OAAO,IAA/C;QACQ,IAAI,CAACD,eAAe,CAACC,OAAO,EAAE,IAAI,CAAE,CAACC,GAAG,CAACH,SAAS,CAAC;QACnD,MAAMI,KAAd,GAAsBF,OAAO,CAACE,KAAK,CAACjF,qBAAqB,CAAC;QAClD,IAAI,CAACiF,KAAb,IAAsBA,KAAK,CAAC,CAAC,MAAMF,OAAO,EAAE;UAClC;UACA,IAAI,CAACrD,aAAa,CAACwD,GAAG,CAACH,OAAO,EAAE,IAAII,MAAM,CAACJ,OAAO,CAAC,CAAC;QACtD;MACF,CAAC,CAAC;IACJ,CAAC,CAAC;EACJ;EAEQ5B,aAAaA,CAACV,QAAgB,EAAxC;IACI,IAAI,CAAC5C,MAAM,CAACkE,IAAI,CAAC,IAAI,CAACzC,YAAY,EAAEmB,QAAQ,CAAC,EAAE;MAC7C,MAAMS,MAAZ,GAAwD,IAAI,CAAC5B,YAAY,CACjEmB,QAAQ,IACN,CAFV,CAEoB;MACdS,MAAM,CAACkB,MAAb,GAAsB,CAAtB,CAAwB;MAElB;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA,IAAIgB,UAAV,GAAuB,IAAI,CAAC5D,YAAY,CAAC6D,GAAG,CAAC5C,QAAQ,CAAC;MAChD,IAAI,CAAC2C,UAAX,IAAyB,IAAI,CAAC1D,aAAa,CAAC4D,IAAI,EAAE;QAC1C;QACA;QACA;QACAF,UAAR,GAAqB,IAAI,CAACN,eAAe,CAACrC,QAAQ,EAAE,IAAI,CAAE;QAClD;QACA;QACA;QACA;QACA;QACA,IAAI,CAACf,aAAa,CAACiC,OAAO,CAAC,CAAC4B,MAAM,EAAEC,KAAK,KAAjD;UACU,IAAID,MAAM,CAACE,IAAI,CAAChD,QAAQ,CAAC,EAAE;YACzB;YACA;YACA;YACA,MAAMiD,eAAlB,GAAoC,IAAI,CAAClE,YAAY,CAAC6D,GAAG,CAACG,KAAK,CAAC;YACpD,IAAIE,eAAe,EAAE;cACnBA,eAAe,CAAC/B,OAAO,CAAEkB,SAAS,IAChCO,UAAW,CAACJ,GAAG,CAACH,SAAS,CAAC,CAC3B;YACH;UACF;QACF,CAAC,CAAC;MACJ;MACA,IAAIO,UAAV,IAAwBA,UAAU,CAACE,IAAI,EAAE;QACjCF,UAAU,CAACzB,OAAO,CAAEkB,SAAS,IAArC;UACU,MAAM;YAAET,MAAM;YAAE,GAAGuB;UAA7B,IAAsC,IAAI,CAACxC,aAAa,CAAC0B,SAAS,CAAC;UACzDpB,MAAM,CAACmC,MAAM,CAAC1C,MAAM,EAAEyC,IAAI,CAAC;UAC3BlC,MAAM,CAACmC,MAAM,CAAC1C,MAAM,CAACkB,MAAM,EAAEA,MAAM,CAAC;QACtC,CAAC,CAAC;MACJ;IACF;IAEA,MAAMyB,KAAV,GAAkB,IAAI,CAACtE,SAAS,CAACkB,QAAQ,CAAC;IACtC,IAAIoD,KAAR,IAAiBA,KAAK,CAACC,MAAM,EAAE;MACzB;MACA;MACAD,KAAK,CAACE,MAAM,CAAC,CAAC,CAAC,CAACpC,OAAO,CAAET,MAAM,IAArC;QACQ,IAAI,CAACe,gBAAgB,CACnBxB,QAAQ,EACRS,MAAM,EACN,IAAI,CAAC5B,YAAY,CAACmB,QAAQ,CAAC,CAAC2B,MAAM,CACnC;MACH,CAAC,CAAC;IACJ;IAEA,OAAO,IAAI,CAAC9C,YAAY,CAACmB,QAAQ,CAAC;EACpC;EAEQuD,cAAcA,CACpBvD,QAA4B,EAC5B5B,SAAiB,EAFrB;IAII,IAAI4B,QAAQ,EAAE;MACZ,OAAO,IAAI,CAACU,aAAa,CAACV,QAAQ,CAAC,CAAC2B,MAAM,CAACvD,SAAS,CAAC;IACvD;EACF;EAEQiE,eAAeA,CACrBC,OAAe,EACfkB,eAAwB,EAF5B;IAII,IAAIC,YAAR,GAAuB,IAAI,CAAC1E,YAAY,CAAC6D,GAAG,CAACN,OAAO,CAAC;IACjD,IAAI,CAACmB,YAAT,IAAyBD,eAAe,EAAE;MACpC,IAAI,CAACzE,YAAY,CAAC0D,GAAG,CAACH,OAAO,EAAGmB,YAAtC,GAAqD,IAAIC,GAAG,CAA5D,CAAuE,CAAC;IACpE;IACA,OAAOD,YAAY;EACrB;EAEOE,eAAeA,CACpBC,QAAqD,EACrD5D,QAA4B,EAC5B6D,MAA4B,EAC5B9F,SAA+B,EAJnC;IAMI,IAAI,CAAC6F,QAAQ,CAACE,aAAa,EAAE,OAAO,IAAI;IAExC;IACA;IACA,IAAI,CAAC9D,QAAQ,EAAE,OAAO,KAAK;IAE3B,MAAMoC,SAAV,GAAsBwB,QAAQ,CAACE,aAAa,CAACC,IAAI,CAACC,KAAK;IACnD;IACA,IAAIhE,QAAR,KAAqBoC,SAAS,EAAE,OAAO,IAAI;IAEvC,IAAI,IAAI,CAAC/C,kBAAb,IAAmC,IAAI,CAACN,YAAY,CAACkF,GAAG,CAAC7B,SAAS,CAAC,EAAE;MAC/D,MAAM8B,oBAAZ,GAAmC,IAAI,CAAC7B,eAAe,CAACrC,QAAQ,EAAE,IAAI,CAAE;MAClE,MAAMmE,SAAZ,GAAwB,CAACD,oBAAoB,CAAC;MACxC,MAAME,YAAZ,GAA4B9B,OAAe,IAA3C;QACQ,MAAMmB,YAAd,GAA6B,IAAI,CAACpB,eAAe,CAACC,OAAO,EAAE,KAAK,CAAC;QACzD,IACEmB,YADV,IAEUA,YAAY,CAACZ,IAAvB,IACUsB,SAAS,CAACE,OAAO,CAACZ,YAAY,IAAI,CAAC,EACnC;UACAU,SAAS,CAAC5C,IAAI,CAACkC,YAAY,CAAC;QAC9B;MACF,CAAC;MAED;MACA;MACA;MACA;MACA;MACA;MACA,IAAIa,wBAAV,GAAqC,CAAC,EAAET,MAAxC,IAAkD,IAAI,CAAC5E,aAAa,CAAC4D,IAAI,CAAC;MACpE,IAAI0B,qBAAV,GAAkC,KAAK;MAEjC;MACA;MACA,KAAK,IAAIC,CAAA,GAAI,CAAC,EAAEA,CAAA,GAAIL,SAAS,CAACd,MAAM,EAAE,EAAEmB,CAAC,EAAE;QACzC,MAAMf,YAAd,GAA6BU,SAAS,CAACK,CAAC,CAAC;QAEjC,IAAIf,YAAY,CAACQ,GAAG,CAAC7B,SAAS,CAAC,EAAE;UAC/B,IAAI,CAAC8B,oBAAoB,CAACD,GAAG,CAAC7B,SAAS,CAAC,EAAE;YACxC,IAAImC,qBAAqB,EAAE;yBACzBvH,SAAS,CAACyH,IAAxB,MAEgBzE,QAFhB,EAGgBoC,SAHhB,CAIe;YACH;YACA;YACA;YACA;YACA;YACA8B,oBAAoB,CAAC3B,GAAG,CAACH,SAAS,CAAC;UACrC;UACA,OAAO,IAAI;QACb;QAEAqB,YAAY,CAACvC,OAAO,CAACkD,YAAY,CAAC;QAElC,IACEE,wBADV;QAEU;QACA;QACAE,CAAA,KAAML,SAAS,CAACd,MAA1B,GAAmC;QACzB;QACA;QACA;QACA;QACAhG,yBAAyB,CAACuG,QAAQ,CAACc,YAAY,EAAEb,MAAO,EAAE9F,SAAS,CAAC,EACpE;UACA;UACA;UACA;UACAuG,wBAAV,GAAqC,KAAK;UAChCC,qBAAV,GAAkC,IAAI;UAE5B;UACA;UACA;UACA;UACA,IAAI,CAACtF,aAAa,CAACiC,OAAO,CAAC,CAAC4B,MAAM,EAAE6B,WAAW,KAAzD;YACY,MAAMnC,KAAlB,GAA0BxC,QAAQ,CAACwC,KAAK,CAACM,MAAM,CAAC;YACpC,IAAIN,KAAhB,IAAyBA,KAAK,CAAC,CAAC,MAAMxC,QAAQ,EAAE;cAClCoE,YAAY,CAACO,WAAW,CAAC;YAC3B;UACF,CAAC,CAAC;QACJ;MACF;IACF;IAEA,OAAO,KAAK;EACd;EAEOC,UAAUA,CAAC5E,QAA4B,EAAE5B,SAAiB,EAAnE;IACI,MAAMqC,MAAV,GAAmB,IAAI,CAAC8C,cAAc,CAACvD,QAAQ,EAAE5B,SAAS,CAAC;IACvD,OAAO,CAAC,EAAEqC,MAAd,IAAwBA,MAAM,CAACE,KAAK,CAAC;EACnC;EAEOkE,iBAAiBA,CAACC,SAAyB,EAApD;IACI,MAAM;MAAE9E,QAAQ;MAAE5B;IAAtB,IAAoC0G,SAAS;IACzC,MAAMrE,MAAV,GAAmB,IAAI,CAAC8C,cAAc,CAACvD,QAAQ,EAAE5B,SAAS,CAAC;IACvD,IAAI2G,cAAkE;IAEtE,IAAIpE,KAAR,GAAgBF,MAAhB,IAA0BA,MAAM,CAACE,KAAK;IAClC,IAAIA,KAAR,IAAiBX,QAAQ,EAAE;MACrB,MAAM7B,OAAZ,GAAsD;QAC9C6B,QAAQ;QACR5B,SAAS;QACTN,KAAK,EAAEgH,SAAS,CAAChH,KAAzB,IAAkC,IAAI;QAC9BC,SAAS,EAAE+G,SAAS,CAAC/G;MAC7B,CAAO;MACD,MAAMF,IAAZ,GAAmBF,sBAAsB,CAACmH,SAAS,CAAC;MAC9C,OAAOnE,KAAK,EAAE;QACZ,MAAMqE,iBAAd,GAAkCrE,KAAK,CAAC9C,IAAI,EAAEM,OAAO,CAAC;QAC9C,IAAIvB,OAAO,CAACoI,iBAAiB,CAAC,EAAE;UAC9BrE,KAAV,GAAkBnD,sBAAsB,CAACwH,iBAAiB,CAAC;QACnD,OAAO;UACL;UACA;UACAD,cAAV,GAA2BC,iBAA3B,IAAgD5G,SAAS;UAC/C;QACF;MACF;IACF;IAEA,IAAI2G,cAAR,KAA2B,KAAK,CAAC,EAAE;MAC7BA,cAAN,GACQD,SAAS,CAAChH,KAAlB,GACUhB,qBAAqB,CAACgI,SAAS,CAAChH,KAAK,EAAEgH,SAAS,CAAC/G,SAAS,IAC1DpB,eAAe,CAACyB,SAAS,EAAET,sBAAsB,CAACmH,SAAS,CAAC,CAAC;IACnE;IAEA;IACA;IACA,IAAIC,cAAR,KAA2B,KAAK,EAAE;MAC5B,OAAO3G,SAAS;IAClB;IAEA;IACA;IACA;IACA,OAAOA,SAAX,KAAyBjB,sBAAsB,CAAC4H,cAAc,IAAIA,cAAlE,GACQ3G,SAAR,GAAoB,GAApB,GAA0B2G,cAAc;EACtC;EAEO3E,SAASA,CACdC,OAAyB,EACzBlC,OAA+B,EAFnC;IAII,MAAM8G,iBAAV,GAA8B5E,OAAO,CAAC6E,IAAI;IACtC,IAAI,CAACD,iBAAiB,EAAE;IAExB,MAAME,WAAV,GAAwB9E,OAAO,CAACvC,KAAhC,IAAyCuC,OAAO,CAACjC,SAAS;IACtD,IAAI,CAAC+G,WAAW,EAAE;IAElB,IAAI9E,OAAO,CAACL,QAAhB,KAA6B,KAAK,CAAC,EAAE;MAC/B,MAAMA,QAAZ,GAAuB7B,OAAO,CAACoC,KAAK,CAAC6E,aAAa,CAC1CH,iBAAiB,EACjB,YAAY,CACb;MACD,IAAIjF,QAAQ,EAAEK,OAAO,CAACL,QAA5B,GAAuCA,QAAQ;IAC3C;IAEA,MAAM+E,cAAV,GAA2B,IAAI,CAACF,iBAAiB,CAACxE,OAAO,CAAC;IACtD,MAAMjC,SAAV,GAAsBjB,sBAAsB,CAAC4H,cAAc,CAAC;IACxD,MAAMzG,QAAV,GAAqBH,OAAO,CAACoC,KAAK,CAAC6E,aAAa,CAC1CH,iBAAiB,EACjBF,cAAc,CACf;IACD,MAAMtE,MAAV,GAAmB,IAAI,CAAC8C,cAAc,CAAClD,OAAO,CAACL,QAAQ,EAAE5B,SAAS,CAAC;IAC/D,MAAM0D,IAAV,GAAiBrB,MAAjB,IAA2BA,MAAM,CAACqB,IAAI;IAElC,IAAIA,IAAI,EAAE;MACR,MAAMuD,WAAZ,GAA0BC,wBAAwB,CAC1C,IAAI,EACJL,iBAAiB,EACjB5E,OAAO,EACPlC,OAAO,EACPA,OAAO,CAACoC,KAAK,CAACgF,UAAU,CACtB/I,WAAW,CAACyI,iBAAiB,IAC3BA,iBAAiB,CAACO,KAA9B,GACYP,iBAAiB,EACnBF,cAAc,CACf,CACF;MAED;MACA,OAAOrH,SAAS,CAACkD,SAAS,CAAC,IAAI,CAAC1B,KAAK,EAAE4C,IAAI,EAAE,CAC3CxD,QAAQ,EACR+G,WAAW,CACZ,CAAoB;IACvB;IAEA,OAAO/G,QAAQ;EACjB;EAEOmH,eAAeA,CACpBzF,QAA4B,EAC5B5B,SAAiB,EAFrB;IAII,MAAMqC,MAAV,GAAmB,IAAI,CAAC8C,cAAc,CAACvD,QAAQ,EAAE5B,SAAS,CAAC;IACvD,OAAOqC,MAAX,IAAqBA,MAAM,CAACqB,IAAI;EAC9B;EAEO4D,gBAAgBA,CACrBC,cAAkC,EAClCvH,SAAiB,EACjBwH,aAAiC,EAHrC;IAKI,IAAInF,MAAR,GAGoB,IAAI,CAAC8C,cAAc,CAACoC,cAAc,EAAEvH,SAAS,CAAC;IAC9D,IAAIyD,KAAR,GAAgBpB,MAAhB,IAA0BA,MAAM,CAACoB,KAAK;IAClC,IAAI,CAACA,KAAT,IAAkB+D,aAAa,EAAE;MAC3BnF,MAAN,GAAe,IAAI,CAACC,aAAa,CAACkF,aAAa,CAAC;MAC1C/D,KAAN,GAAcpB,MAAd,IAAwBA,MAAM,CAACoB,KAAK;IAChC;IACA,OAAOA,KAAK;EACd;EAEOgE,gBAAgBA,CACrBvH,QAAoB,EACpBC,QAAoB,EACpB;IAAET,KAAK;IAAEkC,QAAQ;IAAE6B;EAHvB,CAGyC,EACrC1D,OAAqB,EACrB2H,OAAqB,EALzB;IAOI,IAAIjE,KAAR,KAAkBxD,WAAW,EAAE;MACzB;MACA;MACA;MACA,OAAO0H,wBAAwB,CAAC5H,OAAO,CAACoC,KAAK,CAAC,CAC5CjC,QAAuB,EACvBC,QAAuB,CACxB;IACH;IAEA,IAAIsD,KAAR,KAAkBpD,YAAY,EAAE;MAC1B;MACA,OAAOF,QAAQ;IACjB;IAEA;IACA;IACA;IACA;IACA,IAAIJ,OAAO,CAAC6H,SAAS,EAAE;MACrB1H,QAAN,GAAiB,KAAK,CAAC;IACnB;IAEA,OAAOuD,KAAK,CACVvD,QAAQ,EACRC,QAAQ,EACR+G,wBAAwB,CACtB,IAAI;IACJ;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,KAAK,CAAC,EACN;MACEtF,QAAQ;MACR5B,SAAS,EAAEN,KAAK,CAACiG,IAAI,CAACC,KAAK;MAC3BlG,KAAK;MACLC,SAAS,EAAEI,OAAO,CAACJ;IAC7B,CAAS,EACDI,OAAO,EACP2H,OAFR,IAEmB,CAFnB,CAEqB,CACd,CACF;EACH;AACF;AAEA,SAASR,wBAAwBA,CAC/BvF,QAAkB,EAClBkF,iBAAsD,EACtDH,SAAyB,EACzB3G,OAA+B,EAC/B2H,OAAoB,EALtB;EAOE,MAAMf,cAAR,GAAyBhF,QAAQ,CAAC8E,iBAAiB,CAACC,SAAS,CAAC;EAC5D,MAAM1G,SAAR,GAAoBjB,sBAAsB,CAAC4H,cAAc,CAAC;EACxD,MAAMhH,SAAR,GAAoB+G,SAAS,CAAC/G,SAA9B,IAA2CI,OAAO,CAACJ,SAAS;EAC1D,MAAM;IAAEkI,WAAW;IAAEC;EAAvB,IAAmC/H,OAAO,CAACoC,KAAK;EAE9C,OAAO;IACL1C,IAAI,EAAEF,sBAAsB,CAACmH,SAAS,CAAC;IACvChH,KAAK,EAAEgH,SAAS,CAAChH,KAArB,IAA8B,IAAI;IAC9BM,SAAS;IACT2G,cAAc;IACdhH,SAAS;IACTvB,WAAW;IACXyJ,WAAW;IACXH,OAAO;IACP5G,KAAK,EAAEa,QAAQ,CAACb,KAAK;IACrBgH,OAAO;IACP9F,SAASA,CAAI,GAAGvC,IAAW,EAA/B;MACM,OAAOkC,QAAQ,CAACK,SAAS,CACvBE,yBAAyB,CAACzC,IAAI,EAAEoH,iBAAiB,EAAElH,SAAS,CAAC,EAC7DI,OAAO,CACR;IACH,CAAC;IACDK,YAAY,EAAEuH,wBAAwB,CAAC5H,OAAO,CAACoC,KAAK;EACxD,CAAG;AACH;AAEA,gBAAgBD,yBAAyBA,CACvC6F,aAAoB,EACpBlB,iBAAsD,EACtDlH,SAA+C,EAHjD;EAKE,MAAM;IAAE,CAAC,EAAEqI,kBAAkB;IAAE,CAAC,EAAElB,IAAI;IAAE7B,MAAM,EAAEgD;EAAlD,IAA2DF,aAAa;EAEtE,IAAI9F,OAAyB;EAE7B,IAAI,OAAO+F,kBAAb,KAAoC,QAAQ,EAAE;IAC1C/F,OAAJ,GAAc;MACRjC,SAAS,EAAEgI,kBAAkB;MAC7B;MACA;MACA;MACAlB,IAAI,EAAEmB,IAAZ,GAAmB,IAAInB,IAAvB,GAA8BD;IAC9B,CAAK;EACH,OAAO;IACL5E,OAAJ,GAAc;MAAE,GAAG+F;IAAnB,CAAuC;IACnC;IACA;IACA,IAAI,CAAChJ,MAAM,CAACkE,IAAI,CAACjB,OAAO,EAAE,MAAM,CAAC,EAAE;MACjCA,OAAO,CAAC6E,IAAd,GAAqBD,iBAAiB;IAClC;EACF;EAEA,IAAIxI,OAAN,IAAiB4D,OAAO,CAAC6E,IAAzB,KAAkC,KAAK,CAAC,EAAE;eACtClI,SAAS,CAACyH,IAAd,MAEM1H,mBAAmB,CAACuJ,KAAK,CAACpB,IAAI,CAACiB,aAAa,CAAC,EAC9C;EACH;EAEA,IAAI,KAAK,MAAM9F,OAAO,CAACtC,SAAS,EAAE;IAChCsC,OAAO,CAACtC,SAAZ,GAAwBA,SAAS;EAC/B;EAEA,OAAOsC,OAAO;AAChB;AAEA,SAAS0F,wBAAwBA,CAC/BxF,KAAsB,EADxB;SAGS,SAAS/B,YAAYA,CAACF,QAAQ,EAAEC,QAAQ,EAAjD;IACI,IAAI3B,OAAO,CAAC0B,QAAQ,KAAK1B,OAAO,CAAC2B,QAAQ,CAAC,EAAE;MAC1C,MAAMtB,iBAAZ,KAAkE;IAC9D;IAEA;IACA;IACA;IACA;IACA,IAAIJ,eAAe,CAACyB,QAAQ,KAAKzB,eAAe,CAAC0B,QAAQ,CAAC,EAAE;MAC1D,MAAMgI,KAAZ,GAAoBhG,KAAK,CAAC6E,aAAa,CAAC9G,QAAQ,EAAE,YAAY,CAAC;MACzD,MAAMkI,KAAZ,GAAoBjG,KAAK,CAAC6E,aAAa,CAAC7G,QAAQ,EAAE,YAAY,CAAC;MACzD,MAAMkI,WAAZ,GAA0BF,KAA1B,IAAmCC,KAAnC,IAA4CD,KAA5C,KAAsDC,KAAK;MAErD,IAAIC,WAAW,EAAE;QACf,OAAOlI,QAAQ;MACjB;MAEA,IAAI/B,WAAW,CAAC8B,QAAQ,KAAKhB,uBAAuB,CAACiB,QAAQ,CAAC,EAAE;QAC9D;QACA;QACA;QACAgC,KAAK,CAACsB,KAAK,CAACvD,QAAQ,CAACkH,KAAK,EAAEjH,QAAQ,CAAC;QACrC,OAAOD,QAAQ;MACjB;MAEA,IAAIhB,uBAAuB,CAACgB,QAAQ,KAAK9B,WAAW,CAAC+B,QAAQ,CAAC,EAAE;QAC9D;QACA;QACA;QACA;QACAgC,KAAK,CAACsB,KAAK,CAACvD,QAAQ,EAAEC,QAAQ,CAACiH,KAAK,CAAC;QACrC,OAAOjH,QAAQ;MACjB;MAEA,IACEjB,uBAAuB,CAACgB,QAAQ,KAChChB,uBAAuB,CAACiB,QAAQ,CAAC,EACjC;QACA,OAAO;UAAE,GAAGD,QAAQ;UAAE,GAAGC;QAAjC,CAA2C;MACrC;IACF;IAEA,OAAOA,QAAQ;EACjB;AACF","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}